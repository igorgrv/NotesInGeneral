# Pós - Arquitetura e Desenvolvimento Java

Matrícula: **RM430091** (vi96)

Email: rm430091@fiap.com.br **(DtNasc#080396)**



## Lives

* Canivete Suiço? **Quais ferramentas escolher para o dia a dia de um backend**. :heavy_check_mark:
  *  https://zoom.us/rec/share/yyeoHiEZ6clMt3Qi4to4hJwRLxnJOkVdpBDQmQECiW5W8NCELYBLLsR7ex1t59lz.CJ0xaB8vht5RSf3A  
  * `7h3\*Xm@N`
* SOAP vs REST vs gRPC: **Qual devo usar para criar a API** :heavy_check_mark:
  * https://zoom.us/rec/share/tQEJjH2DdiQ0IxkkOg_rEv7SPNdKzQegzsauiQXj5VsxtxluTD7s6lSYQcw2OX59.eElEMw44ytxmQIAI  
  * `!R2B4H%$`
* LIVE EXTRA - Projeto Coda Comigo -  **Utilização do Lombok/Validação com Bean Validation** :heavy_check_mark:
  * https://zoom.us/rec/share/lhQpqQa31owzO6Qta7jZxUQAci7FcpoomeSa6iH7GMm40rMgPfLGrpEjCKVTv3D3.dFGDEikLo7AjRaqk?startTime=1686783690000
  * `$=AZ6&.H`
*  LIVE EXTRA - Projeto Coda Comigo - **DTO/Records** :heavy_check_mark:
  * https://zoom.us/rec/share/u0cY9y-15Qfm7E_iqotPxzdG5Q73fjwWEeHMa15W0LjZv9LKqDlPIEL3mpXXuble.82l50Sh6L0hFEKDw?startTime=1687387944000
  * `8&7%wd#O`

* LIVE EXTRA - Projeto Coda Comigo - **Testes Unitários e Validação de Beans** :heavy_check_mark:
  * https://zoom.us/rec/share/vhCyPyXU6B6TAxdHAiXIsJsQgqf3cluIjkWWBnAwfB4cOkVByDABprKLz7suL3kl.BtvHrx32KkWvbp7b 
  * `8*%SH^HE`

* Live de Persistência 1: **Introdução ao SQL e PostgresSQL** :heavy_check_mark:
  * https://zoom.us/rec/share/XO_PSbk7B6JdkGTgvP8c2JgheEntsnKkokjdb4X-dTPfYvX9P1D0TkyS-yDZfIo0.Pl_H1WY4q-VOA7dq 
  * `28cC+%x0`

* Live de Persistência 2: **Mapeamento de Entidades JDBC** :heavy_check_mark:
  * https://zoom.us/rec/share/Jr92C0GFQ_RaTXi61m4kxzPNVvPSXoFGyNOQvPJqU6vfQOvGiI3hTXdflvlexu4R.p_zpC_r38RoSjcwj 
  * `Q3.j@rqa`
* Live de Persistência 3 + 4: **Consultas com Spring JPA + Relacionamentos :heavy_check_mark:**
  * [https://zoom.us/rec/share/1rzC337hD5Xwo-CpstiaHAaNA3Ml_lieRx-9ZdgJnqmvlAY4l3JrRj4ccP6qMqHR.Iqj0gaZqqu9Dw13_](https://zoom.us/rec/share/1rzC337hD5Xwo-CpstiaHAaNA3Ml_lieRx-9ZdgJnqmvlAY4l3JrRj4ccP6qMqHR.Iqj0gaZqqu9Dw13_)
  * `=aq!B2Y9`

* Live de Persistência 5: **Relacionamentos One to One e One to Many no JPA** :heavy_check_mark:
  * https://zoom.us/rec/share/HSUMl9Jsz1cO74hl799NmphzDKgAsu6EM4Fn2ZzjDY31ppChhwnDKv8rNxkn59D_.S8DqwjyPY1J7Ld3i 
  * `g4c!dS?Z`

* Live de Persistência 6: **Introdução ao JPQL** :heavy_check_mark:
  * https://zoom.us/rec/share/dMcCbmBfJTvDED9F5QDmWijctCMPBtnAl7TiHsXxeS6A2eTqQHubMbr7AvN_Nyes.nlQ-y-TERsZKPnV3 
  * `asUpp0?3`

* Live: Dominando Deploys :heavy_check_mark:
  * https://zoom.us/rec/play/TwpDfRDBo3ECl3J4UFoJc2hdHHfzqYgnhgQV0ec5PkSImaeIm83kVUyD-HipTwqZ3GF1d1-kaeJWBERZ.b7JBnJoQutf1xOJW?canPlayFromShare=true&from=recording_mg&continueMode=true&iet=ufWhVy3WaurrlpCIYANb5ax-FTSSDdnlG1kkpA6QOD4.AG.Bj1-tP8zJFxVljFA9-mnrldGsUCrXfxZ9Y1i3FrzJHh7FfjSZJ-UlCyLrybNz0m_qyXRC46PIpqM5JNcM9waiQPEyhWCSX2uAwGnwWjiJ3bCfs1AuxvOE4eMSEG9kvkvBKxmQVjn5g.4TlXsoAuySS4zLN_ogqquw.CsN21ab7qbfZg2mb&componentName=rec-play&originRequestUrl=https://zoom.us/rec/share/gtYrKfGvrrSnbxHec20p2mORi-EF4wi7WMltwgCgPAlZ0ZYGhQKimp1B1t3hQTeq.dlkP-LeQ00jU0ckW?iet=ufWhVy3WaurrlpCIYANb5ax-FTSSDdnlG1kkpA6QOD4.AG.Bj1-tP8zJFxVljFA9-mnrldGsUCrXfxZ9Y1i3FrzJHh7FfjSZJ-UlCyLrybNz0m_qyXRC46PIpqM5JNcM9waiQPEyhWCSX2uAwGnwWjiJ3bCfs1AuxvOE4eMSEG9kvkvBKxmQVjn5g.4TlXsoAuySS4zLN_ogqquw.CsN21ab7qbfZg2mb
  * `8#N#wy@!`

* Live: Deploy Contínuo
  * https://zoom.us/rec/share/4JOAqpww4ldd_O5iWqlIbFEHvC4dA8vt1Jzv6sOU7ZoL6od8T5k5d3MLMcecchrO.rPztykLkIrN2EujB?startTime=1695248440000
  * `8wBe@YBd`

## April 27 - Aula Inaugural 00

* Gustavo Genari - CEO FIAP
* Paulo Vieira - CEO Alura
* Adriano Almeida - COO Alura
* Andrea Paiva - Head/Diretora MBA On
* Vlad Cruz - Professor
* Cassio Oliveira - Coordenador

Curso dividido em 5 fases. No Final do curso haverá um desafio final com tudo que foi aprendido, com **hackathon**.

1. Primeiros passos com Spring
2. DDD e testes automatizados
3. Requisitos, portabilidade e qualidade de Software
4. Deploy e mensageria
5. Spring JPA e desenvolvimento seguro

Aulas:

* Cada 15 dias tem live

Testes:

* Fast Test - Questões de múltipla escolha
* Desafio - final de fase
  * E.g: Construir um app para cadastro de cliente (interface)
  * Webservice / Persistencia
* Hackathon
* Fase 5 é necessário ir presencial, marcar

Notas:

* Fast Test
* Tech Challenge
* Hackaton
* Atividade Presencial<img src="./imageResource/notas.png" alt="Screenshot 2023-04-27 at 19.58.27" style="zoom:30%;" />



**Desafio 1**

https://forms.office.com/pages/responsepage.aspx?id=4r_bEbiJSUW-EM7DZOWVUcuxE3m2i81CkgE7F-PZ4k5UMFY4RTVZR0FKTlNKN1IwRTUzMVdLREkzRi4u

* 70 questões múltipla escolha, conceito, leutura e intepretação de código
  * 1 só correta
  * Pesos diferentes
  * 20:45 - termina



# Fase 1 - First Steps w/ Spring

Projeto git: https://github.com/FIAP/PostTech_Java_AluraBank

## Aula 1 - Motivação & REST & HTTP

* HTTP são todas conexões que realizamos em um browser para acessar um site;
* Para acessar uma requisição HTTP precisamos:
  * Tipo de requisição:
    * HTTP é o tipo de requisição - HTTPS é a requisição HTTP + Protocolo SSL de criptografia;
  * Endereço da requisição:
    * Todo servidor possui um número global, que quando acessado um domínio (google) é direcionado para o número 123.456.789
* **Response**: resposta do servidor
* **Header**: Utilizado na requisição para passar mais informação, como o tipo de resposta (JSON/TEXT/XML), Token de autenticação. Todo header tem um tamanho máximo default por servidor (tomcat é 8kb).
* **APIs**: Application Programming Interface, é um mecanismo que permite que duas aplicações de linguagens distintas se comuniquem, mas para isso uma série de definições e protocólos sejam definidos nas requisições e respostas
  * Tipos de APIs:
    * **SOAP**: client e sevidor utilizam XML para trocar dados;
    * **RPC**: Remote Procedure Call - permite que um app chame procedimento de outra função;
    * **Websocket**: conexão bidrecional entre servidor e cliente, para trocarem informações (jogos e chats);
    * **REST**: Transferencia Representacional de Estado - Cliente solicita informações ao servidor, que o processa e devolve para o cliente;
      * Benefícios:
        * Integração
        * Inovação
        * Expansão
        * Facilidade de Manutenção

```bash
Resumo da aula part 1:

Professor Rodrigo Vieira e o Paulo Silveira apresentaram o funcionamento de uma comunicação HTTP.
Assim como os seres humanos conversam entre si em uma linguagem que ambos entender, assim funciona os computadores.

Um protocólo serve para ambos conversarem, onde uma:
- Requisição
- Resposta
Devem acontecer...

Por padrão quando acessamos uma página, fazemos:
- Verbo HTTP (GET)
- Endereço (https://xxxxxx.com.br) -> URL (nome único) Uniform Resource Locator
- Body + header (opcionais)

Retorno:
- Status code (200, 404, 302)
- Response

Para testar podemos fazer via cURL

curl -i -X GET https://alura.com.br
-i -> queremos detalhes
-X -> método HTTP

Algumas requisições são bloqueadas por falta de certificado
```

```bash
Resumo da aula parte 2:

GET com parâmetros pode ser feito com o curl tbm
➜  ~ curl -i -X GET "https://postman-echo.com/get?nome=igor&idade=27"
HTTP/2 200
date: Thu, 04 May 2023 01:03:20 GMT
content-type: application/json; charset=utf-8
content-length: 354
etag: W/"162-hbyVcNEljpowYSxiiK4cobBye+g"
set-cookie: sails.sid=s%3AiMVw_ReiXxsiUvrEo1R2fPfIfNBETTOC.Fq76U4YkBbBbpRWH5e3DCcocmkrEJAVz7ssXQd5Hz7E; Path=/; HttpOnly

{
  "args": {
    "nome": "igor",
    "idade": "27"
  },
  "headers": {
    "x-forwarded-proto": "https",
    "x-forwarded-port": "443",
    "host": "postman-echo.com",
    "x-amzn-trace-id": "Root=1-64530458-439776466e260d2a564c0cf4",
    "user-agent": "curl/7.87.0",
    "accept": "*/*"
  },
  "url": "https://postman-echo.com/get?nome=igor&idade=27"
}%


Para fazer POST também podemos passar parâmetros com o curl, iremos passar outros valores:
-d -> para o body
-H -> para o Header

➜  ~ curl -i -X POST https://postman-echo.com/post -H "Content-Type:application/json" -d '{"chave1":"value1","chave2":"value2"}'
HTTP/2 200
date: Thu, 04 May 2023 01:09:37 GMT
content-type: application/json; charset=utf-8
content-length: 520
etag: W/"208-s4iYVSWcMJoCJA9nf9ZLn5k6a8E"
set-cookie: sails.sid=s%3AumBo_JZDgxovCUB_XrY1-wxA0udgcuNx.Xo0kdWh1LjGmbTgtw0kLst7Dr%2B9neQJUJePBc092Gg0; Path=/; HttpOnly

{
  "args": {},
  "data": {
    "chave1": "value1",
    "chave2": "value2"
  },
  "files": {},
  "form": {},
  "headers": {
    "x-forwarded-proto": "https",
    "x-forwarded-port": "443",
    "host": "postman-echo.com",
    "x-amzn-trace-id": "Root=1-645305d1-60d7361e3061a4bf07d6cd95",
    "content-length": "37",
    "user-agent": "curl/7.87.0",
    "accept": "*/*",
    "content-type": "application/json"
  },
  "json": {
    "chave1": "value1",
    "chave2": "value2"
  },
  "url": "https://postman-echo.com/post"
}%
```

Status Codes: https://httpcats.com/



## Aula 2 - Spring

* Spring foi criado pela empresa Pivotal, como um projeto java open source
* Objeto principal era facilitar o desenvolvimento, implementando o conceito de **injeção de dependência + inversão de controle.**
  * Surgiu para substituir o então **J2EE**, que era bom para criação de aplicações.
* Spring não precisa de um **servidor de aplicação** para funcionar;
* Spring podemos criar aplicações **reativas, batchs, web apps, apps cloud, apps serveless**;



### Projetos Spring

* **Spring Boot**: forma mais rápida de criação de apps;
  * Cria apps stand-alone;
  * Internaliza servidores de aplicação como tomcat, jetty (sem precisar do war);
  * Configura automaticamente o Spring e libs terceiros
  * Sem necessidade de códigos ou xml;
* **Spring Framework:** é o core para injeção de dependencias, webapps;
* **Spring Data:** feito para lidar com banco de dados relacionais, não relacionais, cloud;
* **Spring Security:** framework para autenticação e autorização, customizável;



### Spring Boot

* Para que o Spring Boot funcione, é necessario 4 tipos de componentes:
  * **Spring Boot Starter:** Combina várias bibliotecas em uma só, sem que aja a necessidade de adicionar várias dependências. Exemplo, quando adicionamos o spring mvc, já adicionamos também o web, core, mvc e servlet API.
  * **Spring Boot CLI:** CLI é utilizado como uma linha de comando para iniciar o Spring Starter e AutoConfigurator
  * **Spring Boot AutoConfigurator:** gerencia as configurações do Spring, permitindo configurações personalizadas;
  * **Spring Boot Actuator:** Prove os endpoints e as métricas + responsável por definir que o servidor fique exposto na porta XYZ;



### Spring Initializr

* É uma ferramenta que ajuda na criação de um projeto Spring Boot - https://spring.io/projects
* Para utiliza-lo precisamos definir:
  * Maven ou Gradle
  * Java ou Kotlin
  * Versão do Spring Boot
  * Empactamento:
    * **JAR** (Java Archive) - mais usual, é um zip com as bibliotecas utilizadas no projeto, utilizada em outros projetos java;
    * **WAR** (Web Application Archive) - é um zip voltado para web, muito usado pelo antigo **Tomcat**;
  * Dependências (Spring MVC, WEB, REACTIVE, CLOUD, DATA);



### Como era sem o Spring...

A injeção de dependências foi o que tornou o Spring tão popular. Antes do Spring, era muito comum o uso de um padrão chamado **REGISTRY**, onde a idéia é criar uma classe `static` que **fabrica os objetos**.

```java
public class Registry {
  
  public static final Evento getEvento() {
    return new Evento(getEscola(), new LocalDoEvento());
  }
  
  public static final Escola getEscola() {
    return new Escola();
  }
}
```

* O Registry tende a crescer conforme mais classes são criadas;
* O Registry permite o uso Global das classes (má prática e grande problema nos apps mais antigos) - já que basta chamal-lo e teremos acesso a classe;
* Favore o **acoplamento!**
  * ***Se sua classe possui vários imports de classes diferenetes do projeto, ISSO É SINAL DE ACOPLAMENTO!***

#### @Component

Basicamente, invés de **termos o registry, o Spring veio com um simples `@Component`** para resolver a injeção das dependencias!

* @Component é anotação mais básica, que pede ao Spring ***Gerencie para mim essa classe/injete automaticamente ela***

## Aula 3 - Gerenciador de dependências

* Quando temos uma série de classes que fazem sentido entre si, podemos **considera-la do mesmo pacote!**
* O uso de biblioteca veio para validar o termo **para que recriar a roda?** Se alguém já desenvolveu determinada função, basta implementar-los ela;
* **Problema dos pacotes antigamente:** 
  * quando usamos muito e precisamos atualiza-los, como fazemos? temos que ir manualmente em cada pacote e ir atualizando cada um deles :sweat:
  * Uma biblioteca precisa de outra, que precisa de outra e assim por diante...
* Os gerenciadores de dependencia/pacotes vieram para resolver este problema.
  * **Java: Maven / Gradle**
  * Javascript: NPM / Yarn
  * .NET: NuGet
  * Python: PIP

### Maven

Desenvolvido pela **Apache**, maven através do arquivo **pom (Project Object Model)** pode configurar todas as dependências do projeto;

* Maven segue o **`CoC`** (**Convention over Configuration**) - que estipula um padrão de estrutura para cada folder, onde o maven já sabe onde procurar os files
* Os arquivos baixados pelo maven ficam dentro do diretório **`.m2`**;
* Ciclos:
  * **`mvn compile` -> Gera os . class**
  * `mvn test`
  * **`mvn package` -> Gera o Jar**
  * **`mvn install` -> Roda todos steps anteriores**
* Arquivos gerados pelo maven vão para pasta `target` do projeto;
* Se executarmos um `java -jar fileCriadoPeloMaven.jar` será iniciado o projeto;

**Pros**:

* Gerenciador Java **mais conhecido e mais antigo**;
* Maior parte dos projetos utilizam;
* Fácil de ler (XML);
* Processo de build simplificado (`man package` | `mvn install`)

**Cons:**

* Necessita instalação ( `brew install mvn`);
* Díficil de escrever (por ser XML);

### Gradle

Desenvolvido pela **Gradle**, junta as mesmas dependências do **Maven e Ivy**.

* Utilizado em **projetos Android**;
* Utiliza a linguagem **Groovy**; (ou seja precisa saber uma nova linguagem para criar o arquivo)

```groovy
apply plugin: 'java' 
apply plugin: 'eclipse' 
apply plugin: 'application' 

mainClassName = 'hello.HelloWorld' 

repositories { 
  mavenCentral() 
} 

jar { 
  archiveBaseName = 'gs-gradle' 
  archiveVersion = '0.1.0' 
}

sourceCompatibility = 1.8 
targetCompatibility = 1.8 
dependencies { 
  implementation "joda-time:joda-time:2.2" 
  testImplementation "junit:junit:4.12" 
}
```



## Aula 4 - Coesão e Acoplamento

*Um projeto precisa ser entregue, porém sempre com qualidade! Um fator determinante é a **coesão e acoplamento.*** Alguns projetos não se preocupam com a reutilização de códigos, **mas na orientação a objetos este é o tema central!**

* **Acoplamento:**
  * O quanto um **componente depende do outro** é o que define o **grau de acoplamento**.
  * **Componente depende muito de outro = Alto acoplamento; :x:**
  * **Problema:** difícil de dar manutenção, uma alteração pode ter um efeito cascata em outros componentes.
  * **Tipos:**
    * **Desenvolvimento:** Um componente depende do outro, podendo gerar um **efeito cascata**;
    * **Semântica**: Quando 2 componentes compartilham do mesmo conceito no projeto;
    * **Funcional**: Quando 2 componentes precisam executar juntos uma função;
    * **Incidental**: Quando 2 componentes estão juntos sem uma real necessidade;
    * **Operacional**: Quando um componente precisa de outro para realizar uma tarefa;
* **Coesão:**
  * Se o **acoplamento se preocupa com o externo** (relação entre 2+ componentes), a **coesão se preocupa com o interno**, ou seja, o que aquele componente X está fazendo.
  * Pensando no UNO, imagine que a carta **6 vermelha tem uma única função!** Tem uma cor + número... mas como seria se uma carta pudesse mudar de cor, número e fizesse outras coisas?
  * **Componente com muita responsabilidade = Baixa coesão;** :x:



## Aula 6 - Annotations

* No Java os primeiros ***metadados*** foram criados para preenchimento da **javadoc.** 

* A partir do JSR 175, foram introduzidas as ***annotations*** (defindas pelo **`@`**), que permitiam que metadados fossem atribuídos a métodos, classes, campos, parâmetros e etc;

* Spring faz muito o uso das annotations, como em:

  * `@RestController` -> Indica que se trata de uma classe que para uma API Rest;

  * `@RequestMapping` -> endereço da API

  * `@JsonProperty` -> Informa ao Spring que deverá ser feito um binding do parâmetro para json

    * ```java
      public class myEntity {
        
        @JsonProperty
        private String name;
        
        @JsonProperty
        private int age;
      }
      
      // { name:'igor', age: 27}

## Aula 7 - MVC

* Quando pensamos que um **projeto poderá sofrer alterações no futuro**, ou quando pensamos em **qualidade**, o padrão mais conhecido é o **MVC (Model View Controller)**.
  * **Controller**: Cuida das rotas;
  * **View**: O que é apresentado ao usuário;
  * **Model**: É o objeto, onde fica a regra de negócio;
* Criado em 1970, para projetos visuais.
* Controller recebe a requisição, chama a camada de negócio (Model) e então devolve uma View;



**MUITOS PROJETOS NÃO DIVIDEM BEM A LÓGICA DE NEGÓCIO E TECNOLOGIA**!

* Lógica de negócio **DEVE ficar na classe de domínio!**
* Lógica de tecnologia, deve ficar nas classes Services/Controllers

# Fase 1 - Criação de API Rest w/ SpringBoot

## Aula 1 - Chamando a API

* Existem algumas formas de se "chamar" uma API, o GET talvez seja o mais simples, **podemos utilizar o próprio browser!** porém não podemos utilizar os outros métodos HTTP;
  * O Chrome possui plugins para chamadas REST, como o ***Advanced Rest Client***.
* Quer fazer **via terminal? Existe o CURL!** Porém, é massivo ficar digitando os comandos...
* Softwares? Temos **Postman & Insomnia**! User friendly, quer nos permite fazer todas chamadas, salva-las em collections e etc...

## Aula 2 - Injeção de dependência

* Antes de falar sobre injeção de dependência, precisamos entender ***O quê é uma dependência?***
  * **Dependência é um objeto do qual OUTRO objeto depende!** simples assim :smiley:
* Quando de como uma dependência é utilizada, **pode ficar muito difícil dar manutenção**. Para isso foi criado a chamada ***Injeção de dependência***, que **remove o acoplamento** entre objetos/dependentes.



### Sem injeção de dependência

Dado o exemplo:

```java
public class MyService {
  
  private CalculadoraDeImpostosNacionais calculadora = new CalculadoraDeImpostosNacionais();
  
  public BigDecimal calculaImposto(int valor) {
    return this.calculadora.calcula(valor);
  }
}
```

* `MyService` **depende** da classe `CalculadoraDeImpostosNacionais`, pq para executar o `calculaImposto` se faz necessário utilizar o método `calcula` da `CalculadoraDeImpostosNacionais`.

  * O que aconteceria se precissássemos de mais calculadoras? **Talvez `MyService` pudesse receber no construtor a Calculadora?** Sim, mas o ideal seria com uma interface, **pois a interface não exige que seja instanciada,**  tirando assim a **dependência de `MyService` da `Calculadora`**

    ```java
    public interface CalculadoraDeImpostos {
      BigDecimal calcula(int valor);
    }
    ```

    ```java
    public class MyService {
      
      private CalculadoraDeImpostos calculadora;
      
      // constructor
      // quem quiser usar MyService, pode passar a classe que quiser que implemente a interface...
      public MyService(CalculadoraDeImpostos calculadora) {
        this.calculadora = calculadora;
      }
      
      public BigDecimal calculaImposto(int valor) {
        return this.calculadora.calcula(valor);
      }
    }
    ```



### W/ Injeção de dependência - Autowired

* O Spring lida com a injeção de forma diferente. Através de containers chamado `Spring IoC`. Ele consegue manipular todas as dependências.

* **`@Autowired`** (ponto de dependência) -> pode ser utilizada e atributos/Setters

  * ```java
    @Service
    public class MyService {
      
      @Autowired
      private CalculadoraDeImpostos calculadora;
      
      public BigDecimal calculaImposto(int valor) {
        return this.calculadora.calcula(valor);
      }
    }



## Aula 3/4 - DTOs

* DTO ou ***Data Transfer Object*** é nada mais do que uma **abstração da regra de negócio/entidade**.

* Porque usar?

  * Imagine a classe ***User***:

  * ```java
    public class User {
      private String name;
      private Integer age;
      private boolean admin;
    }
    ```

  * Imaginando que temos um controller que salva o usuário, poderíamos **deixar vulnerável nosso sistema**, pois um hacker poderia "tentar" simular no JSON que temos um parametro chamado ***admin*** :thinking:

  * ```json
    {
      'name': 'Igor',
      'age': 27,
      'admin': true
    }
    ```

  * Com o uso de DTO podemos abstrair o parâmetro `admin` , fazendo assim, com que mesmo que seja passado admin no JSON, ele será **ignorado!**

  * ```java
    public record UserDTO(String name, Integer age){}
    ```



Como bom padrão para o DTO, devemos coloca-lo **próximo a Controller!** E seguindo o principío SOLID, o DTO será responsável em retornar a Entidade!

```java
//DTO
public record UserDTO(String name, Integer age){
  
  public User toUser() {
    return new User(name, age)
  }
}


//ENTITY
public class User {
  private String name;
  private Integer age;
  private boolean admin;
  
  public User(String name, Integer age) {
    this.name = name;
    this.age = age;
  }
}
```





# Fase 2 - DDD e Tests

Fast-test:

1. E
2. E
3. E
4. E
5. B

## Aula 1 - Intro Domain Driven Design

* DDD (*Domain Driven Design*) é uma **padrão de design de software**.
* **NÃO PRECISAMOS USAR TUDO DO DDD**;
* Nos ajuda **não sair escrevendo código SEM PLANEJAMENTOS**; (**GOHORSE!**)
* Enfatiza a colaboração com um **domain expert** (uma ou mais pessoas) e um time de desenvolvedores, **para entender o domínio/goal** do projeto;

<img src="./imageResource/subDomain.png" alt="subDomain" style="zoom:50%;" />



### Design Estratégico

* Por quê?
  * Por que fazer XPTO?
* O quê?
  * O quê vamos fazer?
* Como?
  * Último step, no como fazer...

### Subdomínio Principal

*Heart of the business* / *core do negócio*

* Em uma *escola* o **domínio é a educação!** é o Foco, missão principal da escola
* É o que faz o seu projeto **ser** **diferente**;



### Subdomínio de Genérico

É todo **processo em comum com o resto do mercado**, é algo que **não fará diferença** no seu projeto, como:

* Folha de pagamento;
* Contabilidade;
* Autenticação;

É onde fica uma lógica complexa, **mas** que não é a principal...



### Subdomínio de Suporte

* Não afeta teu projeto se isso der problema...
  * O software de Folha de pagamento está fora do ar, **podemos fazer via Excel**;



## Aula 2 & 3 - Storytelling

* Nada melhor do que entender o que **há de ser feito** com um conto de histórias!
* Nada melhor do que uma história escutada por diferentes perspectivas, traga pessoas para contar sobre X assunto;

**Todo domínio** começa com um *conto de histórias*, que contém **atores, objetos e ações**

* **atores:** são as peças fundamentais do domínio; *Cliente, usuário, atendente*
* **objetos**: é o meio, pode ser físico ou digital; *planilha, ticket, sistema de vendas*
* **ação**: é a interação entre **atores e objetos**; Cliente acessa o sistema de vendas;
  * usamos verbos!




Quando usamos *storytelling*, é importante **numerarmos as ações**, para que exista uma ordem naquela história.

* É o caminho feliz, ***sem if-else***
* Utilize **pictogramas**, imagens que ilustram como objetos / ações agem

<img src="./imageResource/ddd2.png" alt="ddd2" style="zoom:50%;" />

**ATENÇÃO:** quando escutamos a história de um ***domain expert***, temos que separar:

* ***AS IS***: como é hoje / realidade atual
* ***TO BE***: como será / desejo / realidade futura



Contar histórias nos ajuda:

* Entender o domínio;
* Estabeler uma linguagem em comum com o Domain Expert e o IT Expert;
* Esclarescer mal entendido;
* Desenhar processos de negócio;



Integrantes principais:

* **Domain expert**: quem irá contar a história
* **Ouvintes:** todos que estão disponíveis a aprender a história (developers);
* **Moderador**: quem irá fazer as perguntas ao domain expert e n deixar o assunto correr;
* **Modelador**: quem irá fazer os pictogramas e fazer as anotações



Outro exemplo com numerações, atores, ações e objetos:

![storytelling](/./imageResource/storytelling.png)

* Precisa descrever um ***if else*** dentro desse fluxo? **CRIE UM NOVO CENÁRIO!**



Novo cenário na visão do **time de admissão**

![storytelling2](./imageResource/storytelling2.png)

* Com anotações/dicionário para entender a linguagem do time!



Mesmo cenário, porém na visão do **time de marketing**

![storytelling3](./imageResource/storytelling3.png)

* Leads = Responsáveis = Pais = Prospects
  * ![storytelling 4](./imageResource/storytelling 4.png)



* É de extrema importância que haja um **a linguagem ubíqua** / linguagem em comum entre os envolvidos de diferentes áreas

Existem ferramentas **WiKi** para nos ajudar a mapear  / catalogar os modelos

* Notion.io

O que é importante de se ter na **WiKi**:

* Wiki central do projeto, que consolida todas as demais wikis;
* Wiki com descrição do projeto;
* Uma página para cada subdomínio (um para cada time do projeto);
* Seção na wiki para **linguagem ubíqua**/**dicionário**;
* Seção para os cenários que criamos, premissas e limitações;
* Link para os repositórios
* Link para ferramenta de gestão do projeto;



## Aula 4 - Contexto Delimitados

Existem diversos modelos de contextos delimitados e como eles se interagem:

* **Parceria**
  * Trabalham juntos, uma mudança é conversada com o outro
  * Em microserviços trabalham com contratos
  * <img src="./imageResource/parceria.png" alt="parceria" style="zoom:50%;" />
* **Kernel Compartilhado:**
  * **Se evite ao máximo!** É quando 2 times trabalham em uma mesma função de sub-domínios/contextos diferentes
  * Comunicação é essencial! Para evitar código duplicado, ou quebrar algo do outro lado
    * <img src="./imageResource/kernel.png" alt="kernel" style="zoom: 50%;" />
* **Cliente Fornecedor**
  * Aceita o que o fornecedor (upstream) faz, se ele altera, o cliente (downstream) altera
    * <img src="./imageResource/clientFornecedor.png" alt="clientFornecedor" style="zoom:50%;" />
* **Camada Anti-Corrupção (ACL)**
  * Faz uma interface de meio de campo, entre o client e o fornecedor, assim se alguma alteração acontece no fornecedor, não precisam todos os sistemas serem alterados
  * Como um JDBC para o Banco
  * <img src="./imageResource/acl.png" alt="acl" style="zoom: 50%;" />
    * AWS possui o Keyclock, que se integra com Google, Facebook e etc, fazendo o. trabalho de ACL para os times
* **Linguagem Publicada (PL)**
  * É o oposto do que acontece com o Cliente Fornecedor. Neste modelo o fornecedor se adequa ao cliente
* **Caminho Separado**
  * Muitas vezes apesar dos contextos terem algo em comum, pode acontecer do business ou time técnico decidirem cada um seguir com o seu desenvolvimento



No Final, iremos ter um **MAPA DE CONTEXTO**, onde se junta diversas camadas e tipos de Contextos (junção de PL, ACL e etc)

![mapa de contexto](./imageResource/mapa de contexto.png)



## Aula 5 - Arquitetura e Lógica

![arqLogica](./imageResource/arqLogica.png)

* **Designed Tático**:

  * É onde fica o `como` do DDD, é a parte prática, aqui definimos a linguagem, tecnologia, tipos de banco de dados (relacionao ou não), microserviços ou barramento e como se interagem

* **Camada de interface de usuário (GUI)**:

  * É onde fica a interface do usuário, interface de comando (CLI) e as APIs

* **Camada de aplicação**:

  * Aqui não fica a lógica de negócio e tbm n se altera estado de objetos, mas fica a parte de monitoramento que irá reportar as mudanças a outras camadas.
  * Aqui ficam os gatilhos de atualização do sistema. (***cronjob***)

* **Camada de Domínio**:

  * É o core da aplicação (conceitos de negócio), aqui ficam os objetos e onde eles são alterados (é oq diferencia a aplicação, ***o segredo***).
    * Exemplo: onde fica a lógica da nota dos alunos, planos de aula e etc

* **Camada de Infra**:

  * É a camada que da suporte as camadas superiores, é onde fica a mensageria por exemplo

  

  ![arqLogica2](./imageResource/arqLogica2.png)

  

## Aula 6 - Event Storming

O Event Storming é a atividade prática, onde chamamos:

* Domain Experts: irá descrever as atividades
* Ouvintes: querem aprender sobre a história (developers)
* Facilitador: que vai conduzir



Nela iremos preencher:

* **EV** -> Eventos (atividades **escritas no passado**);
* **CM** -> Comandos (o que triga o evento, **escrita no presente**);
* **AT** -> Atores (pessoas que executam Comandos);
  * **PL** -> Política (sistema que faz o papel do ator, de trigar algum comando);
* **PA** -> Ponto de Atenção (são as perguntas relacionada ao evento);
* **ML** -> Modelo de Leitura (é a interface)<img src="./imageResource/eventStorming.png" alt="eventStorming" style="zoom: 50%;" />



Dessa forma podemos criar os **agregados**, que são como as entidades irão se conversar

![eventStormingContexto](/Users/igorgomesromerovilela/Development/NotesInGeneral/Java/graduate/imageResource/eventStormingContexto.png)



# Fase 2 - Docker

* O Docker surgiu como uma melhoria da então chamada **Maquina Virtual**
* Para criar uma máquina virtual, é necessário fazer toda a instalação do Sistema Operacional (40 minutos no mínimo);
* Docker vem com o conceito de **container**, onde permite **executar um sistema** de forma isolada com **somente as dependência/bibliotecas daquele sistema**.
* Para configurar um container usamos **Dockerfile**, ali ficará instruções para criação do container!
* **Docker Hub** é o **repositório de imagens**, ali nós podemos subir até mesmo **imagens personalizadas**, ou usar imagens que empresas fornecem (openjdk, python e etc);



## Entendendo comandos

* **`FROM`** -> aqui referenciamos a imagem que vamos usar
* **`WORKDIR`** -> Definimos o diretório que iremos partir (igual ao `cd /folderX`)
* **`RUN`** -> Executa em **tempo de criação da <u>imagem</u>**, qualquer comando, como se estivessemos no terminal
* **`CMD`** -> Executa em **tempo de criação do <u>container</u>** - permite que o comando seja sobreescrito
* **`ENTRYPOINT`** -> Executa em **tempo de criação do <u>container</u>** - NÃO permite que o comando seja sobreescrito
* **`EXPOSE`** -> Utilizado para expor uma porta
* **`COPY`** -> Copia arquivos ou pastas na criação da imagem
* **`VOLUME`** -> Na criação da imagem referenciamos onde irá ficar os metadados;

```dockerfile
FROM ubuntu:22.10

RUN apt-get update
RUN apt-get install nginx -y

VOLUME ["/var/www/html"]

WORKDIR "/var/www/html/"

COPY "index.html" "index.html"

ADD "https://images.pexels.com/photos/1521304/pexels-photo1521304.jpeg" "foto.jpeg"
# Como baixamos o arquivo precisamos alterar a
# permissão para que seja possível acessá-lo
RUN chmod 644 foto.jpeg

ENTRYPOINT ["/usr/sbin/nginx", "-g", "daemon off;"]

EXPOSE 80
```



## Docker Compose

* Precisa gerenciar +1 container?
* Precisa rodar +1 container junto?

Use o **Docker Compose!**

O Docker Compose é configurado **atarvés de um arquivo `docker-compose.yml`**, onde podemos declarar:

* Serviços (db, APIs, frontend, backend) -> aqui vão as imagens do Docker/Dockerfile;
* Volumes
* Secrets
* Portas

### Comandos

| Descrição comando                                        | Comando                                |
| -------------------------------------------------------- | -------------------------------------- |
| Executar Docker Compose com arquivo `docker-compose.yml` | `docker compose up`                    |
| Para não segurar o terminal na execução                  | `docker compose up -d`                 |
| Executar Docker Compose com arquivo customizado          | `docker compose -f FILENAME.yml up -d` |
| Parar Docker Compose                                     | `docker compose down`                  |



### Exemplo

```yaml
services:
  db:
    # We use a mariadb image which supports both amd64 & arm64 architecture
    image: mariadb:10.6.4-focal
    # If you really want to use MySQL, uncomment the following line
    #image: mysql:8.0.27
    command: '--default-authentication-plugin=mysql_native_password'
    volumes:
      - db_data:/var/lib/mysql
    restart: always
    environment:
      - MYSQL_ROOT_PASSWORD=somewordpress
      - MYSQL_DATABASE=wordpress
      - MYSQL_USER=wordpress
      - MYSQL_PASSWORD=wordpress
    expose:
      - 3306
      - 33060
  wordpress:
    image: wordpress:latest
    volumes:
      - wp_data:/var/www/html
    ports:
      - 80:80
    restart: always
    environment:
      - WORDPRESS_DB_HOST=db
      - WORDPRESS_DB_USER=wordpress
      - WORDPRESS_DB_PASSWORD=wordpress
      - WORDPRESS_DB_NAME=wordpress
volumes:
  db_data:
  wp_data:
```



## Docker Network

Como trabalhar compartilhar uma rede entre containers???

* O Docker fornece um driver padrão de rede, chamado **bridge**. Quando não especificamos o tipo de rede, o Docker irá automaticamente criar os containers e associara mesma rede.



Devemos sempre ter alguns cuidados com network:

* Mapear portas iguais! -> irá dar conflito
* Esquecer de mapear as portas! 



### Comandos

Para criar uma rede customizada:

```bash
docker network create my-test
```

Para associar um container já existente a uma rede

```bash
docker network connect minha-rede meu-container
# docker netword connect my-test frontend-app
```



### Exemplo

```bash
#irá criar uma rede chamada 'shared-network'
docker network create shared-network

#irá iniciar um BancoDeDados na rede 'shared-network'
docker run --name db --network shared-network -e POSTGRES_PASSWORD=password -d postgres

#irá iniciar um App Python  na rede 'shared-network'
docker run --name python-app --network shared-network -d python:3.8 bash

#Acessa o app python e instala as libs
docker exec -it python-app bash
pip install psycopg2-binary
```

De dentro do container `python-app` iremos criar um código python que irá **acessar o container `db`**

```python
import psycopg2

conn = psycopg2.connect(
    host="database",
    database="postgres",
    user="postgres",
    password="password")

cursor = conn.cursor()
cursor.execute("SELECT * FROM <table_name>")
rows = cursor.fetchall()	

for row in rows:
    print(row)

conn.close()
```

Com arquivo criado:

```bash
python <nomedoarquivo>.py
```



# Fase 3 - Deploys



## Deploy local

No java, o deploy local se dá pelo `jar` file, gerado pelo `mvn build` (dentro da pasta `target`).

* Executando o programa (necessário java instalado):

```java
java -jar nomeDoSeuJar.jar
```

* O `war` é para subir no Tomcat;



Com Docker:

```dockerfile
FROM maven:3.8.4-openjdk-17-slim AS build

WORKDIR /app

COPY . /app

RUN mvn package

FROM openjdk:17-jdk-slim

COPY --from=build /app/target/*.jar /app/app.jar

ENTRYPOINT ["java", "-Djava.security.egd=file:/dev/./unrandom", "-jar", "/app/app.jar"]
```



```bash
docker build -t nomeDaImagem .
docker run -d -p 3000:80 nomeDaImagem
docker logs serieDoContainer
```



## Deploy no ECS (AWS)

ECS (**Elastic Container Service**) é um serviço de container da AWS (SaaS - não precisamos gerenciar containers e etc, ele faz para nós) .

* Para subir a imagem a AWS também oferece o ECR (**Elastic Container Registry**), funciona igual ao **Docker Hub**



### Clusters

O Cluster é um grupo que iremos ter:

* Tipo de EC2 (tipo daque mina)
* Networking



### Task Definition

Aqui vinculamos qual a imagem que será utilizada para criar o app.

* Clique em ***Create Task Definition***
  * **Fargate** -> Para trabalhar com serveless (por requisição)
  * **EC2** -> sobe uma máquina (até 750h sem custo) - mais comum de uso
* Clique em EC2;
* Clique em Add Container;
  * Preencha o nome do container
  * Nome da imagem no docker hub ou no ECR;
  * Mínimo de memória utilizado
  * Portas
  * Variável de ambiente
  * Política de reinicialização



### Service

O Service precisa de uma task, é onde iremos declarar:

* número de Tasks que serão executadas em paralelo
* LoadBalancer

É onde se faz o link entre a Task e o Cluster.



No Service a gente pode configurar o tipo de `Capacity Provider`:

* FARGATE_SPOT é 5x mais barato que o FARGATE, porém a AWS pode matar o serviço a qualquer momento (mas sobe outro), como se fosse um leilão -> **indicado para DEV/STG**



## Deploy Azure (Microsoft)

Conta: https://azure.microsoft.com/pt-br/free/students/ (100$ disponível)



### Web App for Containers

Serviço feito implantar e executar aplicativos em containers.

Possui algumas facilidades:

* Fácil implantação
* Escalabilidade automática
* Integra com outros services da Azure
* Para container simples ou docker-compose



### Azure Container Instance (ACI)

Serviço também de implementar container, porém sem a necessidade de gerenciar a infra (como no ***Web App For Containers***).

Este serviço é ideal para:

* Apps com curta duração;
* Executar de forma isolada;
* Processamento de eventos;
* Apps que não exigem escalabilidade



### Azure Container Apps (ACA)

Cria containers sem um servidor, e se integra com Docker Hub e outros repositórios.

* Não exige necessidade de gerenciar infra
* Serviço serveless da Azure
* App baseado em container



## Deploy Cloud Gratuita

### Render

https://dashboard.render.com/

Render possibilita nos integrarmos com um repositório do GitHub e a partir dele realizar o deploy!

* Necessário ter o Dockerfile

<img src="./imageResource/render.png" alt="render" style="zoom: 33%;" />

**Camada Free**: 512mb / 0.1CPU

* Projeto vinculado com o git, então a todo commit, irá gerar um update na imagem

Projeto ficará com a URL: https://nomedoprojeto.onrender.com



### Heroku

https://www.heroku.com/



### Supabase

https://supabase.com/

É um servidor free para banco de dados

# Fase 3 - Serverless

Ter um servidor on-premisses, significa ter que cuidar de diversas coisas:

* Garantir escalabilidade
* Segurança
* Infraestrutura (times e times de DevOps)
* MUITA PREOCUPAÇÃO

Como começar? com POCs, migrando em partes!



## Serviços Serverless AWS

**IAM**

É onde a gente cria usuário que irão trabalhar em nossos projetos

* Não é uma boa prática usar o usuário root criando instancias e etc
* Cada usuário irá ter uma `access key` , usada para se autenticar

**AWS Lambda:**

* Executa código sem a necessidade de gerenciar servidores;
* Executa pequenas funções criadas por nós
* Executa tarefa que tem curta duração
* Consultar banco, consultar cache
* Funciona com diversas linguagens;
* Invés de deixar um app que irá executar uma função somente um horário (cronjob), pode ser usado Lambdas;
* **Limitado a 15 minutos de execução** por função;
  * Limitado a 3GB de memória;

**AWS Fargate:**

* Executa containers sem a necessidade de servidor;
* **ECS** (Elastic Container Service):
  * Usa o Fargate para executar containers;
  * ou usa o EC2 para executar containers;
  * Mais caro do que EKS, por ser mais prático e fazer coisas para você
* **EKS** (Elastice Kubernetes Service)

**AWS EventBridge:**

* Serviço de integração;
* Step Functions:
  * Pode se criar flows, de uma lambda para S3 e etc

**AWS AppSync**:

* App que possibilita o frontend consumir direto do banco (sem precisar do backend)
* Baseado GraphQL:
  * Funciona com Pub/Sub, mandamos um request e escutamos uma resposta
  * Houve change no banco, recebemos na hora e avisamos o user;

**AWS SQS (Simple Queue Service)**

* Recebe uma mensagem, poem na fila e o consumidor consome;
* Parecido com MQ;

**AWS SNS (Simple Notification Service)**

* Recebe uma notificação e possui vários consumidores consumindo ou também transmite para outra notificação;
* Cria tópicos e pode publicar para um SQS
* Pub/Sub

**AWS API Gateway**:

* Cria endpoints RESTFul para apps sem a necessidade de servidor;
* Executa funções criadas por nós
* Porta de entrada da aplicação
* HTTP API - gerencia as rotas do app
* WebSocket - fica em tempo real rodando
* Por padrão e segurança, se deixa somente o API Gateway público e os demais serviços privados;



Armazenamento:

**AWS EFS (Elastic File System)**:

* Serverless;
* Escalável;
* Volume -> Compartilha informações entre containers;
* Arquivos temporários;

**AWS S3**:

* Escalável;
* Para guardar arquivos como fotos, site estático;
* Fornece APIs para poder armazenar files;



Banco de dados:

**AWS DynamoDB (NoSQL)**:

* Escalável;
* Serverless;
* Se adapta ao fluxo (conexão disponível);
* Parecido com o MongoDB (NoSQL);

**AWS RDS (Relational Data Service)**:

* Pode ser Serverless ou podemos setar as configs do banco de dados;
* Podemos configurar o mínimo;

**AWS Neptune (Graph Database)**:

* É o Banco de dados feito com a idéia de gráficos;
* Relacionamento são criados conforme criação do banco;



Análise de Dados:

**AWS RedShift**



## Custos

Quando migramos do on-premisses para Cloud, **precisamos fazer uma POC para estimar custos**.

Exemplo - ***Empresa de venda de ingressos:***

<img src="./imageResource/awsLambda.png" alt="awsLambda" style="zoom:50%;" />

* API Gateway filtra a req da internet e direciona para Lambda (meio de campo)
  * Faz autenticação e etc
* Lambda irá executar uma função, q pode ser o GET no banco;
* DynamoDB é o Banco que ajusta automaticamente os recursos;



### Lamda

Gratuito:

* 1MM Requests por mês;
* 400GB-seg de tempo computação por mês;

Demais cobranças:

* Por segundo baseado na memória/recurso disponibilizado;
  * Dividido em ARM ou X86
* Armazenamento temporário outros preços;



Para Lamda, o ideal que seja um procssamento rápido, se for demorar, ideal é utilizar containers;

* 15 Min limite;



### API Gateway

Gratuito:

* 1MM de chamadas API por 12 meses;

Custos:

* Divididos em:
  * API RESTFul
  * Websocket
* Baseado na região o preço irá mudar também
* Cobrado por numero de requisições ou **por tempo de execução**
* Armazenamento em Cache, cobrado por GB/hora



### DynamoDB

Gratuito:

* 25GB de armazenamento

Tipos de cobrança:

* On demand: será cobrado por demanda, pode ser baixa ou alta
* Provisionado: já sabemos o quanto iremos usar, mais barato



### AWS Pricing Calculator

É uma calculadora que dá estimativas de preço, nela podemos:

* Selecionar o serviço (lambda, api gateway);
  * Estipular a região;
* número de requisições mês;
* Tipo de máquina (arm/x86);
* Tempo de cada requisição (ms);



## AWS CLI

Além da opção via UI, a AWS fornece meios de criarmos/manipularmos os recursos via CLI: https://aws.amazon.com/pt/cli/

Para utilizar, primeiro precisamos configurar as credenciais:

* Vá para o https://aws.amazon.com/ -> Sign in
* Clique no profile -> Security Credentials
* Create access key
* No Terminal -> `aws configure` e coloque o access key com a chave



## Containers na AWS

Quando temos alguma execução que irá levar mais de 15 minutos, **não podemos usar Lambda**, e para isso a Amazon oferece:

* ECS
* ECR

Junto com o API Gateway podemos expor esse serviço do ECS (que estará rodando com um container)

### ECR

O ECR nos permite subir uma imagem Docker para um registry da amazon, facilitando nossa vida para fazer depois o deploy no ECS

* Com terminal aberto e o AWS CLI configurado:

```bash
aws ecr --region us-east-1 create-repository --repository-name test
```

* O comando irá devolver a URL com o repository

  * ```json
    {
        "repository": {
            "repositoryArn": "arn:aws:ecr:us-east-1:850055427903:repository/parking-meter",
            "registryId": "850055427903",
            "repositoryName": "parking-meter",
            "repositoryUri": "850055427903.dkr.ecr.us-east-1.amazonaws.com/parking-meter",
            "createdAt": "2023-10-27T10:14:14-03:00",
            "imageTagMutability": "MUTABLE",
            "imageScanningConfiguration": {
                "scanOnPush": false
            },
            "encryptionConfiguration": {
                "encryptionType": "AES256"
            }
        }
    }
    ```

* Fazermos login na AWS com o docker

```bash
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin pasteHereURl
```

* Publicamos a imagem

```bash
docker tag nomeDaImagemBuildada pastHereECRURL/nomeDaImagemBuildadaw
docker push pastHereECRURL/nomeDaImagemBuildada
```



### ECS

ECS serve para **Orquestrar a execução de tarefas em containers de forma serverless.**

1. Criar um cluster (conjunto de recursos operacionais)
   1. Nome do cluster -> padrão iniciar com `cl-nomeCluster`
   2. Selecionar tipo de Infra -> **Fargate** (serverless)

2. Criar uma task definition (é onde configuramos os recursos/parametros do container)
   1. Configuramos:
      1. Arquitetura do build da imagem Docker (atenção ao tipo, no mac é ARM64)
      2. Recurso de ram e cpu (mínimo possível funciona)
      3. URL da imagem (ECR)
      4. Porta
      5. Resource Allocation -> aqui informamos o limite máximo que o container pode chegar
      6. Variável de ambiente
      7. Log -> A AWS fornece o CloudWatch, mas é possível por outro servidor de log
      8. Healthcheck -> usado para garantir a saúde do container
      9. Container Timeout -> é onde informamos o mínimo e máximo tempo que o container tem q levar para subir
3. Criar um Service (é onde de fato irá publicar/expor o container com os valores definidos na Task Definition)
   1. Configuramos:
      1. Cluster (que já criamos)
      2. Compute Option (podemos deixar o que criamos para Task)
      3. Network (opcional)
      4. LoadBalancer (opcional)
      5. Replicas (opcional)
      6. AutoScaling (opcional)

Com um Service criado, será exposto um IP Publico de acesso ao ECS!

* Task Execution Role é a função do agente que orquestra/gerencia o container



### API Gateway

Para expor uma API precisamos levar em conta algumas coisas, como:

* Auth
* Rotas/Direcionar rotas

Para iniciar com o API Gateway, precisamos primeiro entender sobre **VPC (Virtual Private Cloud)**



#### VPC (Virtual Private Cloud)

* VPC funciona como uma rede privada da nossa casa, onde teríamos um roteador e vários outros computadores se conectariam via LAN

Exemplo completo:

<img src="./imageResource/vpc.png" alt="vpc" style="zoom:50%;" />

**Criando uma VPC**

1. Iremos precisar informar:
   1. Qual region iremos ter a VPC (us-east-1a/b/c)
   2. Número de subnets público e privado
   3. Se queremos uma VPC exclusiva (placa de rede física dedicada)

**Security Group**

Para controlar o range de IP ou quem acessa tanto o LoadBalancer quanto os clusters, criamos o chamado **Security Group**, e dessa forma mapeamos como componentes se comunicar dentro de uma VPC!

EXEMPLO:

1. Criar um Security Group para LoadBalancer (tudo que for loadbalancer usaria o mesmo grupo)
   1. Em **Inbound rules**, permitiríamos que todo mundo entrasse *Anywhere-ipv4
   2. En **Outbound rules**, permitiríamos que todo mundo entrasse *Anywhere-ipv4
2. Agora para o **Security Group do Cluster**, não permitiríamos o **Inbound** para anywhere, e sim para o **SecurityGroup do LoadBalancer**, assim, garantíamos que somente o loadbalancer acesse os cluters



#### Target Group

Para criarmos um LoadBalancer, precisamos primeiro de um TargetGroup.

Para criar um Target Group precisamos ir em EC2, e ali iremos configurar para `IP Addresses` (uma vez que o ECS se comunica via IP).



#### LoadBalancer

Por se tratar de um uso para o API Gateway, devemos configurar **como Interno**

#### Cluster

Como uma Security Group ja criado, iremos **criar um Cluster** **usando o Security Group do cluster.**

Com o Cluster criado, podemos **aproveitar a Task Definition** que já tivemos e **criar um Service**, também usando a subnet e vpc privada, feita usando os security group do Cluster VPC, e também usando o loadbalancer já criado

#### Criando API Gateway

Com VPC + Security Group (p/ LB e Cluster) + Target Group + LoadBalancer + Cluster/Services criados, está na hora de mapearmos um API Gateway!

* Em **API Gateway**, vamos em `buil` um **HTTP API**, e colocamos o nome da API Name, e `create` -> irá já expor uma URL pública
* Em **Routes**, iremos mapear um ANY -> `/{proxy+}` - dessa forma qualquer nova rota irá usar essa integração.
* Em **Integrations**, iremos criar um `Private Resource` -> Target service como **ALB/NLB** (appliacation lb e network lb)



## Autenticação

### Amazon Cognito

* 50K users ativos por ano é gratuito
* Permite MFA
* Acesso via redes sociais (google, Facebook e etc)!
* Disponibiliza formulário de preenchimento
* Pode segregar usuários (admins e users comuns)
* Possibilita migração
* Escalável



**Criando User Pools**

User Pools é onde colocamos as configs de cadastro dos usuários.

1. **Provider Types**: Cognito user Pool + Federated identify (acesso com Google etc)
2. **Sign in options**: Tipos de sign in, como **por email/usuários/phone**;
3. **Password policy**: Podemos configurar qual tipo de senha;
4. **MFA**: por ou não por MFA
5. **Recover**: podemos setar como recuperar a senha;
6. **Self signup**: permitir que o usuário se cadastre;
   1. Aqui podemos colocar até 50 tipos de atributos do usuário;
7. **Domain**: podemos integrar uma tela ja existente, ou criar uma do cognito do zero

<img src="./imageResource/cognito.png" alt="cognito" style="zoom:30%;" />



## Lambda

Lambda não cobra, mas conforme o uso, ele cobra pelo uso de RAM e CPU

* Lambda recomendado para coisas que não tem uso contínuo!
  * Fez uma chamada, ela retorna de forma rápida algo, não é para ser usado para grande processamento



No lambda iremos colocar **literamente um código!** e este código será executado pela AWS



**Criando Lamda**:

* **Create function**:
  * **Blueprint**, a AWS dá diversos exemplos prontos (chamados **blueprints**) que são códigos prontos para serem executados

<img src="./imageResource/lambdablueprint.png" alt="lambdablueprint" style="zoom:50%;" />

* ​	**Author from scratch**: colocamos a linguagem

* Selecionamos o tipo de arquitetura que será utilizado
* **Lambda function code**, é onde ficará o lamda q será executado

<img src="./imageResource/lambdafunction.png" alt="lambdafunction" style="zoom:50%;" />



## SAM

Deseja testar, criar e implantar aplicativos serverless? AWS oferece o SAM (**Serverless Application Model**)!

* Através de um YAML é possível configurar o ambiente





# Fase 3 - NoSQL MongoDB

* **NoSql** = ***Not Only SQL***
* O MongoDB é um sistema NOSQL
* Ao invés de utilizar dados relacionais, é utilizado o formato JSON ou BSON (binary Json);
* Orientado a Documentos;
* Fornece alta disponibilidade/tolerância falhas;
* Suporta QREP;
* Suporta consulta avançada, incides;

**Estrutura:**

```
Da		tabase
		|_______ Colections
									|_______ Documents
```



## NoSql X Sql

* Quando queremos mais desempenho? 

* O NOSQL NÃO SUBSTITUI O SQL;

* Precisa lidar com dados não estruturados ou semi estruturados?

* Precisa de uma alta velocidade de leitura e gravação?

* Precisa de flexibilidade?

  * Um Documento pode conter:

    * ```json
      {
        "_id":"123",
        "name":"Igor",
        "age":27
      }
      ```

  * Como pode ter:

    * ```json
      {
        "_id":"123",
        "age":27
      }
      ```



### Vantagens NoSql

A maior vantagem do NoSql em relação SQL se dará muito em **como o dado foi estruturado usando NoSql**!

Vamos imaginar a página abaixo:

<img src="./imageResource/nosqlarticle.png" alt="nosqlarticle" style="zoom:30%;" />

* Podemos ter:
  * Autor
  * Artigo
  * Categoria
  * Comentários

Utilizando o SQL teríamos:

<img src="./imageResource/sqlArticle.png" alt="sqlArticle" style="zoom:50%;" />

* Para exibir uma tela, teríamos que realizar pelo menos 3 consultas!

```sql
SELECT artigos.*, autor.name FROM artigos
INNER JOIN autor ON autor.autor_id = artigos.audtor_id
WHERE artigo_url = 'xyz';

SELECT categoria.*, autor.name FROM categoria
INNER JOIN artigo_categoria ON artigo_categoria.idCategoria = categoria.id
WHERE artigo_categoria.id = 'xyz';

SELECT comentario.* FROM comentario
WHERE comentario.artigo_id = 'xyz';
```



Com **NoSql os dados podem e devem ser duplicados em um único documento**!

* Pelo NoSql ser muito performático, o melhor uso dele é colocar tudo que uma tela precisa em um único documento
  * **ATENÇÃO!** quando for atualizar o nome do Autor por exemplo, precisará atualizar todos documentos de outras collections que possuem o nome daquele Autor!

```json
{
    _id: ObjectId("64a495d6896e49abd95879e8"),
    title: 'Title do artigo',
    categoria: "Categoria x", 
    author: {
      "_id": ObjectId("123")
       "name": "Igor Romero",
       "email": "igorgrv@hotmail.com"
 		},
    comentarios: [
      {
	      "_id": ObjectId("123"),
        "body":"meu comentario"
      }
    ]
}
```



## Tipos de relacionamentos

Sim, Nosql tem relacionamentos!

* Incorporação
* Referência (referencia chave valor, um documento vai ter a chave do outro)
* Desnormalização

### Incorporação

Quando um Documento incorpora/possui outro documento

Exemplo - **Usuário vs Postagens**

```json
{
  "_id": ObjectId("user1"),
  "nome": "João",
  "idade": 25,
  "postagens": [
    {
      "_id": ObjectId("post1"),
      "titulo": "Primeira postagem",
      "conteudo": "Conteúdo da primeira postagem"
    },
    {
      "_id": ObjectId("post2"),
      "titulo": "Segunda postagem",
      "conteudo": "Conteúdo da segunda postagem"
    }
  ]
}
```



### Referência:

Como o nome diz, um documento referencia o outro por Id:

```json
{
  "_id": ObjectId("user1"),
  "nome": "João",
  "idade": 25,
  "postagens": [
    ObjectId("post1"),
    ObjectId("post2")
  ]
}
```



### Desnormalização

Basicamente se trata de **duplicar dados** de um documento em vários, para melhorar o desempenho das consultas (evitando buscas em diversos documentos)

* Usado quando pensamos no que uma página irá exibir (trazemos somente as informações q a página precisa);
* Útil quando se tem consultas frequentes, que exigem acesso rápido aos dados;
* Melhora o desempenho das consultas
* **Contras: ocupa mais espaço no banco e cria redundância de dados**

Exemplo - trazer a última postagem do usuário:

```json
{
  "_id": ObjectId("user1"),
  "nome": "João",
  "idade": 25,
  "ultimaPostagem": {
    "_id": ObjectId("post2"),
    "titulo": "Segunda postagem",
    "conteudo": "Conteúdo da segunda postagem"
  }
}
```



## Instalando CLI

MongoDb Community Server: https://www.mongodb.com/try/download/community

Mac: 
```shell
$ brew install mongodb-atlas
$ atlas setup
```

Depois de instalar, tente:

```bash

```

Se retornar
```bash
➜  /usr mongosh
Current Mongosh Log ID:	651f5f0ce4f49732716ff4f7
Connecting to:		mongodb://127.0.0.1:27017/?directConnection=true&serverSelectionTimeoutMS=2000&appName=mongosh+2.0.1
MongoNetworkError: connect ECONNREFUSED 127.0.0.1:27017
```

Tente pausar e restartar:

```bash
brew services stop mongodb-community
brew services start mongodb-community
```

Resultado esperado:

```bash
➜  /usr mongosh
Current Mongosh Log ID:	651f5f27e507f33d557300d4
Connecting to:		mongodb://127.0.0.1:27017/?directConnection=true&serverSelectionTimeoutMS=2000&appName=mongosh+2.0.1
Using MongoDB:		7.0.2
Using Mongosh:		2.0.1

For mongosh info see: https://docs.mongodb.com/mongodb-shell/

------
   The server generated these startup warnings when booting
   2023-10-05T22:13:11.933-03:00: Access control is not enabled for the database. Read and write access to data and configuration is unrestricted
------

test> show databases
admin   40.00 KiB
config  12.00 KiB
local   40.00 KiB
```



### Instalando MongoDb Compass

Link: https://www.mongodb.com/try/download/compass

<img src="./imageResource/mongodbCompass.png" alt="mongodbCompass" style="zoom:80%;" />

## Comandos NoSql

* Iniciar servidor mongo: **`mongod`**

* Mostrar banco: **`show databases`**

* Selecionar o banco: **`use nomeDoBanco`**

* Criar collection: **`db.createCollection("nomeColecao")`**

  * Precisa estar no banco, com o `use`

* Mostrar colections: **`show collections`**

* Deletar collection: **`db.nomeCollec.drop()`**

* Count documentos de uma collection: **`db.nomeCollection.countDocuments()`**

* Listar documentos: **`db.nomeCollection.find()`**

* Listar com filtro: **`db.nomeCollection.find({},{})`**

  * Find recebe 2 parâmetros:

    * 1. parâmetro: se `{}` irá trazer todos os documentos, seria nosso `WHERE` 
      2. parâmetro: é o que queremos ver, seria nosso `SELECT`

    ```json
    db.customers.find({}, {"_id": 0})
    // significa que queremos todos documentos
    // mas que não mostre o _id
    
    db.customers.find({}, {"_id": 1})
    // irá exibir somente o _id
    ```

  * `LIKE` no NoSql é feito pelo `//`

    ```json
    db.customers.find({nome: '/I/'})
    // podemos por 'i' ao final, para ignorar camelCase
    db.customers.find({nome: '/I/i'})
    ```

  * StartsWith é feito pelo `/^/`

    ```json
    db.customers.find({nome: '/^Ig/i'})
    ```

  * `>=` -> Greater than

    ```json
    db.customers.find({idade: {$gte: 18}})
    ```

  * `AND` por mais de uma busca

    ```json
    db.customers.find( { idade: {$gte: 18}, nome: {$regex: /i/} })
    ```

  * Baseado em um objeto dentro de um **objeto**

    ```json
    // dado: { _id: 123, autor: { nome: igor} } -> busque este elemento
    db.customers.find( {"autor.nome": "igor" })
    ```

  * Baseado em um objeto de um **array**:

    ```json
    // dado: { _id: 123, tags: ["tag1","tag2"] } -> busque tag2
    db.customers.find( {tags: "tag2"})
    ```

* Count + Find: **`db.nomeCollec.find( {atributo: valor} ).count()`**

```json
db.customers.find( {idade: {$gt: 40} } ).count()
```

* Find + Range: **`db.nomeCollec.find({atributo: {$ind:[x,u]} })`**

```json
db.customers.find({idade: {$in:[1,4]} })
```

* Add um documento: **`db.nomeCollection.insertOne({ nome: "test" })`**

* Add vários documentos: **`db.nomeCollection.insertMany([{ nome: "test" },{ nome: "test2" }])`**

  * MongoDb permite criar variáveis temporárias:

    ```bash
    custArray = [{ nome: "test" },{ nome: "test2" }]
    db.customers.insertMany(custArray)
    ```

* Ordernar um documento: **`db.nomeCollection.find().sort({atributo: 1})`**

  * se `1` -> ASC

  * se `-1` -> DESC

    ```json
    db.nomeCollection.find().sort( {nome: 1} )
    ```

* Atualizar um doc: **`db.nomeCollection.replaceOne( {atributo: 'valorAntigo'}, {atributo: 'valornovo'})`**

```json
db.nomeCollection.replaceOne( {nome: 'Igor'}, {nome: 'Igor2', idade: 23})
```

*PERIGOSO! O ideal é fazer um **UPDATE com WHERE***

* Atualizar doc pela chave: **`db.nomeCollection.updateOne( {_id: 123}, {$set: {atrib: valor} })`**

```json
// $set -> altera o dado do elemento/ou inclui caso n exista
// dado: { _id: 123, nome: Tiago }
db.customer.updateOne( {_id: ObjectId("123")}, {$set: {nome: "Igor", Idade: 2} })
// após o set: { _id: 123, nome: Igor, idade: 2}
```

* Atualiza o subdocumento

  ```json
  // dado: { _id: 123, autor: {nome: Igor} } -> troque nome do autor
  db.customer.updateOne( {_id: ObjectId("123")}, {$set: {"autor.nome": "Tiago"} })
  ```

  

* Atualizar TODOS doc: **`db.nomeCollec.update( {}, {$set: {att: valor}}, {multi:true})`**

```json
db.customers.update( {}, {$set: {idade: 0}}, {multi:true})
```

* Remover um campo: **`db.nomeCollection.updateOne( {_id: 123}, {$unset: {atrib: "valor"}})`**

```json
// $unset -> remove o atributo
db.customer.updateOne( {_id: 123}, {$unset: {cidade: "rj"}})
```

* Adicionar um objeto a um array: **`db.nomCol.updateOne( {_id: 123}, {$push: {atrib: "valor"}})`**

```json
// push add objeto a um array
// dado: { title: test, comentario: [] }
// add um objeto array 'comentario'
db.post.updateOne( {_id: 123}, {$push: {comentario : {title: comentTitle} } })
```

* Remover um objeto de um array: **`db.nomCol.updateOne( {_id: 123}, {$pull: {atrib: "valor"}})`**

```json
// $pull remove objeto de um array
// dado: { title: test, comentario: [ { title: comentTitle} ] }
// remova o comentario 'comentTitle'
db.nomeCollection.updateOne( {_id: 123}, {$pull: {comentario : {title: comentTitle} } })
```

* Deletar um doc: **`db.nomeCollection.deleteOne( {atributo: valor} )`**

```json
db.customers.deleteOne( {_id: ObjectId("id")} )
```

* Distinct: **`db.nomeCollec.distinct("atributo")`**

```json
db.customers.distinct("nome")
```

* Count Docs if Exists: **`db.customers.find( {attr: {$exists:true} }).count()`**

```json
db.customers.find( {"nome":{$exists:true}} ).count()
```

* Data: **`ISODate("2023-10-01T01:00:00.00Z")`**

* GROUP BY: **`db.nomeCollec.agregate(operations)`**

  * No exemplo abaixo iremos agregar pelo nome, e queremos fazer uma soma dos counts

    * ```json
      db.customers.agregate( [ {$group: {_id: "name", num_tutorial: {$sum: 1} } } ] )
      ```

  * Se quiseremos somar pelo field `likes`:

    * ```json
      db.customers.agregate([{$group: {_id: "name", num_tutorial: {$sum: "$likes"} }}])
      ```

* INNER JOIN: **`db.nomeCollec.agregate([{ $lookup:{} }])`**

  ```json
  // dado as 2 collections: ORDERS & PRODUCTS faça o innerJoin
  // Order: { _id: 1, productId: 101}
  // Product: { _id: 101, name: "xbox", category: "eletronic"}
  
  db.orders.agregate([{
    $lookup: {
      from: "products",
      localfield: "productId",
      foreignField: "_id",
      as: "product"
    }
  }])
  ```

  * `$project` -> serve para filtrar o que queremos ver do `$lookup`:

    ```json
    db.orders.agregate([{
      $lookup: {
        from: "products",
        localfield: "productId",
        foreignField: "_id",
        as: "product"
      }
    }, {
      $project: {
        _id: 0,
        productName: "$product.name"
      }
    }])
    ```

  * `$match` -> serve para fazer um filtro (`WHERE`) no INNER JOIN:

    ```json
    db.orders.agregate([{
      $lookup: {
        from: "products",
        localfield: "productId",
        foreignField: "_id",
        as: "product"
      }
    },
    {
      $match: {
        "product.category":"eletronics"
      }
    },
    {
      $project: {
        _id: 0,
        productName: "$product.name"
      }
    }])
    ```



## Spring + MongoDB

Spring boot provê:

```xml
<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-data-mongodb</artifactId>
</dependency>
```

Entidade -> usar `@Document` ao invés do `@Entity`:

```java
@Data
@Document
public class Article {}
```

Repository -> usar `MongoRepository`

```java
public interface ArticleRepository extends MongoRepository<Article, String>
```



### Conexão com o banco

* Por default, quando iniciamos o `mongosh` temos o banco de dados `test`:

  ```bash
  ➜  ~ mongosh
  Current Mongosh Log ID:	65232a607cbb8899b6df4cf2
  Connecting to:		mongodb://127.0.0.1:27017/?directConnection=true&serverSelectionTimeoutMS=2000&appName=mongosh+2.0.1
  Using MongoDB:		7.0.2
  Using Mongosh:		2.0.1
  
  For mongosh info see: https://docs.mongodb.com/mongodb-shell/
  
  ------
     The server generated these startup warnings when booting
     2023-10-05T22:13:11.933-03:00: Access control is not enabled for the database. Read and write access to data and configuration is unrestricted
  ------
  
  test>
  ```

Então se subirmos nosso app e adicionar um novo documento, será armazenado no DB `test`!

**Personalizando conexão**

```yaml
spring:
  data:
    mongodb:
      uri: mongodb://localhost/blog
      port: 27017
      username:
      password:
```

acessando via `mongsh` após inserir um documento

```bash
test> use blog
switched to db blog

blog> show collections
article

blog> db.article.find()
[
  {
    _id: ObjectId("65232e6dc8431b18d6db52d0"),
    title: 'Exemplo de Título',
    text: 'Aqui está o texto da entidade.',
    url: 'https://www.exemplo.com',
    createdDate: ISODate("2023-10-08T03:00:00.000Z"),
    status: 1,
    _class: 'com.igor.blognosql.entity.Article'
  }
]
```



### DBRef - Objeto usando outro Objeto

É comum no java um objeto referenciar outro objeto, mas com o MongoDB precisamos anotar com **`@DBRef`**.

Exemplo - Crie a estrutura do documento abaixo:

```json
{
  "title": "Exemplo de Título 2",
  "text": "Aqui está o texto da entidade2.",
  "url": "https://www.exemplo2.com",
  "createdDate": "2023-10-08",
  "status": 1,
  "author": {
    "name": "Igor",
    "biography": "A developer that loves what he does",
    "image": "jpg"
  }
}
```

Entidade `Author`:

```java
@Data
@Document
public class Author {
  
  @Id
  private String id;
  private String name;
  private String biography;
  private String image;

}
```

Entidade `Article`:

```java
@Data
@Document
public class Article {
  
  @Id
  private String id;
  private String title;
  private String text;
  private String url;
  private LocalDate createdDate;
  private Integer status;

  @DBRef
  private Author author;

}
```



### CRUD básico

```java
// Repository
public interface ArticleRepository extends MongoRepository<Article, String> {}

// Service
@Service
@RequiredArgsConstructor
public class ArticleService {

  private final ArticleRepository articleRepository;
  private final AuthorService authorService;
  
  public List<Article> findAll() {
    return articleRepository.findAll();
  }

  public Article findById(String articleId) {
    return articleRepository
        .findById(articleId)
        .orElseThrow(() -> new IllegalArgumentException("Could not find article"));
  }

  public Article create(Article article) {
    if (article.getAuthor() != null) {
      Author author = authorService.findById(article.getAuthor().getId());
      article.setAuthor(author);
    } else {
      article.setAuthor(null);
    }
    return articleRepository.save(article);
  }
  
  public Article update(Article article) {
    return articleRepository.save(article);
  }
  
  public void delete(String articleId) {
    Article article = findById(articleId);
    articleRepository.delete(article);
  }

}


// Controller
@RestController
@RequestMapping("/articles")
class ArticleController {

  @Autowired
  private ArticleService service;

  @GetMapping
  public ResponseEntity<List<Article>> getAll() {
    List<Article> items = new ArrayList<>();
    service.findAll().forEach(items::add);
    if (items.isEmpty())
      return new ResponseEntity<>(HttpStatus.NO_CONTENT);

    return new ResponseEntity<>(items, HttpStatus.OK);
  }

  @GetMapping("{id}")
  public ResponseEntity<Article> getById(@PathVariable("id") String articleId) {
    Article existingItemOptional = service.findById(articleId);
    return new ResponseEntity<>(existingItemOptional, HttpStatus.OK);
  }

  @GetMapping("findByDate")
  public ResponseEntity<List<Article>> getByDateGreaterThan(@RequestParam LocalDate date) {
    List<Article> articles = new ArrayList<>();
    service.findByDateGreaterThan(date).forEach(articles::add);
    if (articles.isEmpty())
      return new ResponseEntity<>(HttpStatus.NO_CONTENT);
    return new ResponseEntity<>(articles, HttpStatus.OK);
  }

  @PostMapping
  public ResponseEntity<Article> create(@RequestBody Article article) {
    Article savedItem = service.create(article);
    return new ResponseEntity<>(savedItem, HttpStatus.CREATED);
  }

  @PutMapping
  public ResponseEntity<Article> update(@RequestBody Article article) {
    Article updatedItem = service.update(article);
    return new ResponseEntity<>(updatedItem, HttpStatus.OK);
  }
  
  @DeleteMapping("{id}")
  public ResponseEntity<Article> delete(@PathVariable("id") String articleId) {
    service.delete(articleId);
    return new ResponseEntity<>(HttpStatus.OK);
  }

}
```





### MongoTemplate - Queries customizadas

E se quisermos fazer queries customizadas, igual temos com:

```bash
db.nomeCollection.find( {createdDate: {$gte: 2023-10-08}} )
```

Para isso usamos do **`MongoTemplate`**!

```java
private final MongoTemplate mongoTemplate;

public List<Article> findByDateGreater(LocalDate date) {
    Query query = new Query(Criteria.where("createdDate").gt(date));
    return mongoTemplate.find(query, Article.class);
}
```

Update:

```java
public void updateArticleUrl(String id, Article article) {
    Query query = new Query(Criteria.where("id").is(id));
    Update update = new Update().set("url", article.getUrl());
    mongoTemplate.updateFirst(query, update, Article.class);
}
```



#### Criteria + Query + MongoTempl

```java
// Find using mongoTemplate
public List<Article> findByStatusDateAndTitle(String status, LocalDate date, String title) {
  Criteria criteria = new Criteria();
  
  criteria.and("date").lte(date);
  if (status != null) criteria.and("status").is(status);
  if (title != null && !title.isEmpty()) criteria.and("title").is(title);
  
  Query query = new Query(criteria);
  return mongoTemplate.find(query, Article.class);
}
```



### @Query

Assim como no SQL, o MongoDb também permite queries customizadas com o **`@Query`**:

* Exemplo: retorne articles de dentro de um range:
  * Com o uso `?X` passamos a sequência dos parâmetros


```java
// repository
public interface ArticleRepository extends MongoRepository<Article, String> {

  @Query("{ $and: [ { 'createdDate': {$gte: ?0}}, { 'createdDate': {$lte: ?1} } ]}")
  List<Article> findByCreatedDateGreaterThanAndLessThan(LocalDate stars, LocalDate ends);
}
```

Simple query com `$eq`:

```java
@Query(value = "{ 'title': { $eq: ?0 } }")
List<Article> findByTitleWithQuery(String title);
```



### Pageable

Funciona igual a como é feito com JPA clássica:

```java
// service
public Page<Article> findAll(Pageable pageable) {
  return articleRepository.findAll(pageable);
}

// Controller
@GetMapping("page")
public ResponseEntity<Page<Article>> getAll(Pageable pageable) {
  Page<Article> articles = service.findAllPageble(pageable);
  return new ResponseEntity<>(articles, HttpStatus.OK);
}
```

Requisição do `Pageable` espera `page=0&size=5`

```http
GET -> http://localhost:8080/pageable?page=0&size=5
```



### OrderBy

Funciona da mesma forma como na JPA:

```java
// repository
public interface ArticleRepository extends MongoRepository<Article, String> {
  
	List<Article> findByStatusOrderByTitleAsc(String title);
}
```

ou com `@Query` podemos passar o `sort`:

```java
@Query(value = "{ 'title': /?0/i }", sort = "{ 'title' : 1 }")
List<Article> findByTitleWithQuery(String title);
```



#### Pageable + Order

Para fazer o sort dentro de um Pageable, faremos uso do objeto `Sort`:

```java
@GetMapping("pageable")
public ResponseEntity<Page<Article>> getAll(Pageable pageable) {
  Sort sort = Sort.by("titles").ascending();
  Pageable pageableSorted = PageRequest.of(pageable.getPageNumber(), pageable.getPageSize(), sort);
  Page<Article> articles = service.findAllPageble(pageableSorted);
  return new ResponseEntity<>(articles, HttpStatus.OK);
}
```



### Group By - Aggregation

Dado os documentos:

```json
[
  {
    "id": "65233c5af93a492cece07770",
    "title": "Exemplo updated",
    "text": "Aqui está o texto updated",
    "url": "https://www.exemplo.com",
    "createdDate": "2023-09-30",
    "status": 0,
    "author": {
      "id": "6523640a2fad9b797e73cd26",
      "name": "Tiago",
      "biography": "A developer that loves what he does",
      "image": "jpg"
    }
  },
  {
    "id": "652a9b66776b9336fb8aadd2",
    "title": "A title",
    "text": "Aqui está o texto da entidade2.",
    "url": "https://www.exemplo2.com",
    "createdDate": "2023-10-08",
    "status": 1,
    "author": {
      "id": "65233c3bf93a492cece0776f",
      "name": "Igor",
      "biography": "A developer that loves what he does",
      "image": "jpg"
    }
  }
]
```

Vamos agrupar por `status` e exibir uma quantidade do agrupamento

1. Precisamos criar uma classe DTO que irá representar o resultado:

   ```java
   @Data
   public class ArticleStatusCount {
     
     private String status;
     private int count;
   }
   ```

2. Com o uso do `TypedAggregation` e `Aggregation`:

   1. `TypedAggregation` espera 3 parâmetros:
      1. Classe base que contém os dados;
      2. O tipo de agregação, usando o `Aggregation` , ou seja, qual field será o `GROUP BY`;
      3. Saída dos dados, como se fosse os campos que ficariam no `SELECT`;
   2. Com o `MongoTemplate` usamos a função `aggregate` que recebe:
      1.  `TypedAggregation` 
      2. Classe DTO de saída

   ```java
   public List<ArticleStatusCount> getStatusCount() {
       TypedAggregation<Article> typedAggregation = 
         	Aggregation.newAggregation(
             Article.class,
             Aggregation.group("status").count().as("quantity"),
             Aggregation.project("quantity").and("status").previousOperation()
       		);
   
       AggregationResults<ArticleStatusCount> result = mongoTemplate.aggregate(typedAggregation, ArticleStatusCount.class);
       return result.getMappedResults();
    }
   ```

   

**Find + Agregação**

Em muitos cenários precisamos fazer um FIND antes de fazer um GROUP BY, no NoSql usamos **Criteria + Aggregation**

1. Crie um DTO que representará a saída
2. Faça o Filtro com Criteria;
3. Crie o `AggregationTyped`
4. Use `MongoTemplate` para agregar o valor e converter o resultado no DTO;

```java
public List<AuthorArticleCount> getArticlesGroupedByAuthorFrom(LocalDate startDate, LocalDate endDate) {
  Criteria criteria = Criteria.where("createdDate")
    .gte(startDate.atStartOfDay())
    .lt(endDate.plusDays(1).atStartOfDay());

  AggregationOperation match = Aggregation.match(criteria);
  AggregationOperation group = Aggregation.group("author").count().as("totalArticles");

  AggregationOperation project = 
    Aggregation.project("totalArticles")
    	.and("author").previousOperation();

  TypedAggregation<Article> typedAggregation = Aggregation.newAggregation(
      Article.class,
      match,
      group,
      project);

  AggregationResults<AuthorArticleCount> result = 
    	mongoTemplate.aggregate(typedAggregation, AuthorArticleCount.class);
  return result.getMappedResults();
}
```



### Concorrência no Mongo

Para lidar com concorrência no mongo, precisamos incluir a dependência:

```xml
<dependency>
  <groupId>org.springframework.boot</groupId>
  <artifactId>spring-boot-starter-data-mongodb-reactive</artifactId>
  <version>3.1.4</version>
</dependency>
```

Adicionar nas entidades um **`@Version`**
```java
@Version
private Long version;
```

E adicionar com **`@Transactional`** todos os métodos de CRUD do Service:

* Se for métodos de find, basta colocarmos `@Transactional(readOnly = true)`

```java
@Transactional(readOnly = true)
public List<Article> findAll() {
  return articleRepository.findAll();
}
```

* Métodos de Update, Delete, Insert:

```java
@Transactional
public Article create(Article article) {
  if (article.getAuthor() != null) {
    Author author = authorService.findById(article.getAuthor().getId());
    article.setAuthor(author);
  } else {
    article.setAuthor(null);
  }
  return articleRepository.save(article);
}
```



#### OptimisticLockingFailureException

Quando passamos a utilizar o `version` no body, o Mongo irá lidar com as versões do documento, onde se algo for alterado no documento, será incrementado o `version`.

* Com o uso do `version` podemos lidar com diferentes usuários alterando o mesmo documento!
* Caso um usuário altere o mesmo documento, com a mesma `version`, será lançado uma excessão, **`OptimisticLockingFailureException`**

Para lidar com este problema, precisamos criar um handler para exception!

```java
@RestControllerAdvice
public class CustomExceptionHandler {

  @ExceptionHandler(OptimisticLockingFailureException.class)
  public ResponseEntity<Object> handleException(OptimisticLockingFailureException ex) {
    Error error = new Error(HttpStatus.CONFLICT.value(),
        "Error: this document was already changed by another user. Please try again");
    return ResponseEntity.status(HttpStatus.CONFLICT).body(error);
  }

  private record Error(int statusCode, String message) {}
}
```



#### Optimistic handle

Retornar a exception para o usuário não é o ideal, podemos:

1. Verificar com `try/catch` se houve a exception;
2. Se houve a exception, podemos recuperar o documento com a version mais atualizada;
3. Alterar os dados que foram passados pelo usuário;
4. Salvar o documento com a version atualizada manualmente;

```java
public Article update(Article article) {
  try {
    return articleRepository.save(article);
  } catch (OptimisticLockingFailureException e) {
    Article articleUpdated = findById(article.getId());
    articleUpdated.setAuthor(article.getAuthor());
    articleUpdated.setCreatedDate(article.getCreatedDate());
    articleUpdated.setStatus(article.getStatus());
    articleUpdated.setVersion(articleUpdated.getVersion() + 1);

    return articleRepository.save(article);
  }
}
```



### Bean Validation

Assim como um banco SQL, no MongoDB Podemos continuar fazendo as validações dos atributos que vão em um documento:

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-validation</artifactId>
</dependency>
```

E nas classes podemos ter os validadores:

```java
@Data
@Document
public class Article {

  @Id
  private String id;

  @NotBlank(message = "Title is required")
  private String title;

  @NotBlank(message = "Text is required")
  private String text;

  @NotBlank(message = "url is required")
  private String url;

  @NotNull(message = "createdDate is mandatory")
  @DateTimeFormat(pattern = "YYYY-MM-dd")
  @Past
  private LocalDate createdDate;

  @NotNull(message = "Status is required")
  private Integer status;

  @DBRef
  private Author author;

  @Version
  private Long version;

}
```

E na controller precisamos sempre por **`@Valid`**:

```java
@PostMapping
public ResponseEntity<Article> create(@Valid @RequestBody Article article) {
  Article savedItem = service.create(article);
  return new ResponseEntity<>(savedItem, HttpStatus.CREATED);
}
```



# Fase 4 - Testes / Clean Code / WebFlux

Dependências:

```xml
<dependency>
  <groupId>org.junit.jupiter</groupId>
  <artifactId>junit-jupiter-api</artifactId>
  <version>5.10.1</version>
  <scope>test</scope>
</dependency>
<dependency>
  <groupId>org.assertj</groupId>
  <artifactId>assertj-core</artifactId>
  <version>3.24.2</version>
</dependency>
```

Staticos:

```java
import static org.junit.jupiter.api.Assertions.assertEquals;
import static org.assertj.core.api.Assertions.assertThat;
import static org.assertj.core.api.Assertions.catchThrowable;
```

 VSCode - `settings.json`:

```json
"java.completion.favoriteStaticMembers": [
    "org.assertj.core.api.*",
    "org.assertj.core.api.Assertions.*",
    "org.junit.Assert.*",
    "org.junit.Assume.*",
    "org.junit.jupiter.api.Assertions.*",
    "org.junit.jupiter.api.Assumptions.*",
    "org.junit.jupiter.api.DynamicContainer.*",
    "org.junit.jupiter.api.DynamicTest.*",
    "org.mockito.Mockito.*",
    "org.mockito.ArgumentMatchers.*",
    "org.mockito.Answers.*"
  ],
```





## JUnit

Dependêcias:

* `<scope>test</scope>` = significa que somente irá ser carregada quando rodarmos testes

```xml
<!-- JUNIT ESTÁ DEPRECATED - USAR ORG.JUNIT.JUPITER -->
<!-- 
<dependency>
  <groupId>junit</groupId>
  <artifactId>junit</artifactId>
  <version>4.13.2</version>
</dependency> -->
<!-- ORG.JUNIT.JUPITER - necessario para Intellij -->
<!-- <dependency>
  <groupId>org.junit.jupiter</groupId>
  <artifactId>junit-jupiter-engine</artifactId>
  <version>5.10.1</version>
  <scope>test</scope>
</dependency> -->
<dependency>
  <groupId>org.junit.jupiter</groupId>
  <artifactId>junit-jupiter-api</artifactId>
  <version>5.10.1</version>
  <scope>test</scope>
</dependency>
```



### assertEquals

```java
import static org.junit.jupiter.api.Assertions.assertEquals;

import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;

class CalculadoraTest {

  Calculadora calculadora;

  @BeforeEach
  public void setup() {
    this.calculadora = new Calculadora();
  }

  @Test
  public void deveSomar() {
    int resultado = calculadora.soma(3, 2);
    assertEquals(5, resultado);
  }

  @Test
  public void deveSubtrair() {
    int resultado = calculadora.substracao(3, 2);
    assertEquals(1, resultado);
  }
}
```



### assertThrows

Se sabemos que o método também lança uma exception dado um problema, então usamos `assertThrows`

```java
@Test
public void deveDividir() {
  assertThrows(ArithmeticException.class, () -> {
    int resultado = calculadora.divisao(10, 0);
    assertEquals(5, resultado);
  });
}
```



## AssertJ

O AsserJ melhora a sintaxe do JUNIT

```xml
<dependency>
  <groupId>org.assertj</groupId>
  <artifactId>assertj-core</artifactId>
  <version>3.24.2</version>
</dependency>
```

### assertThat

```java
import static org.assertj.core.api.Assertions.assertThat;

@Test
public void deveSomar() {
  int resultado = calculadora.soma(3, 2);
  assertThat(resultado).isEqualTo(5);
}
```

Existem diversos tipos de `assetThat`:

```java
// para save
assertThat(savedMessage)
        .isInstanceOf(Message.class)
        .isNotNull()
        .isEqualTo(message);

// para findById
assertThat(messageOptional)
        .isPresent()
        .containsSame(message);

// para findAll
assertThat(resultado)
        .hasSize(2)
        .containsExactlyInAnyOrder(mensagem1, mensagem2);
```



### isInstanceOf

Para capturar a exception e também a mensagem da exception, podemos:
```java
@Test
public void deveDividir() {
  Throwable exception = catchThrowable(() -> calculadora.divisao(10, 0));
  assertThat(exception).isInstanceOf(ArithmeticException.class);
}
```

ou validando a mensagem:

```java
@Test
public void deveDividir() {
  Throwable exception = catchThrowable(() -> calculadora.divisao(10, 0));
  assertThat(exception).isInstanceOf(ArithmeticException.class).hasMessage("divide by zero");
}
```



### doNothing()

As vezes não queremos q o mockito realize alguma operação, para isso temos o **`doNothing()`**

```java
// para o deleteBy
doNothing().when(mensagemRepository).deleteById(id);
```



### assertThatThrowBy

Considerando que o `findPostById` lance uma exception, podemos:

```java
assertThatThrownBy(() -> postService.findPostById(UUID.randomUUID()))
      .isInstanceOf(RuntimeException.class)
      .hasMessageContaining("UUID not found");
```





## TDD

TDD = ***Test Driver Development***, ou Desenvolvimento Orientado a Testes, envolve:

1. Partimos do Teste/criamos uma hipótese
2. Teste irá falhar
3. Fazemos o teste funcionar
4. Refatoramos

<img src="./imageResource/tdd.png" alt="tdd" style="zoom:80%;" />

Exemplo:
```java
// Primeiros fazemos falhar:
@Test
public void devePermitirRegistrarInformacao(){
  Assert.fail("teste não implementado")
}

@Test
public void devePermitirConsultarInformacao(){
  Assert.fail("teste não implementado")
}
```



### @BeforeAll / @Before / @After

```java
class ClasseTest {
 	@BeforeAll
  public void beforeClass(){
    LOG.info("inicio dos testes")
  }
  @Before
  public void beforeTest(){
    LOG.info("antes do teste")
  }
  @Test
  public void testA(){
    LOG.info("teste A")
  }
  @Test
  public void testA(){
    LOG.info("teste B")
  }
  @After
  public void afterTest(){
    LOG.info("depois do teste")
  }
  @AfterAll
  public void afterClass(){
    LOG.info("finaliza testes")
  } 
}

// inicio dos testes
// antes do teste
// teste 1
// depois do teste
// teste b
// depois do teste
// finaliza testes
```



## Mockito

Por default, o mockito no spring boot vem incluído na dependência:
```xml
<dependency>
  <groupId>org.mockito</groupId>
  <artifactId>mockito-core</artifactId>
  <version>3.12.4</version>
</dependency>
```

* Mockito/Dublê, serve para **simular** **chamadas ao banco de dados**

Para simular o banco, vamos incluir o H2:

```xml
<dependency>
  <groupId>com.h2database</groupId>
  <artifactId>h2</artifactId>
  <version>2.2.224</version>
  <scope>test</scope>
</dependency>
```

`application-test.yaml`:

```yaml
spring:
  datasource:
    url: jdbc:h2:mem:testdb
    driverClassName: org.h2.Driver
    username: admin
    password: 
  jpa:
    database: h2
    database-platform: org.hibernate.dialect.H2Dialect
    defer-datasource-initialization: true
    hibernate.ddl-auto: create-drop
    properties.hibernate:
      show_sql: true
      format_sql: true
      globally_quoted_identifiers: true
```



### Setup

Config default para o Mockito;

```java
class MessageRepositoryTest {
  
  @Mock
  private MessageRepository messageRepository;

  AutoCloseable openMocks;

  @BeforeEach
  void setup() throws Exception {
    openMocks = MockitoAnnotations.openMocks(messageRepository);
  }

  @AfterEach
  void teardown() throws Exception {
    openMocks.close();
  }
}
```



### when()

Para **simular** a chamada ao repositório utilizamos o `when()`

* `when(repository.save(objeto)).thenReturn(objeto);`

  ```java
  class RepositoryTest {
    @Mock
    private MessageRepository messageRepository;
    
  	// setup comentado
    
     private Message generateMessage() {
      return Message.builder()
        .uuid(UUID.randomUUID())
        .user("user 1")
        .message("message is 123")
        .build();
    }
  
    @Test
    void mustSaveMessage() {
      Message message = generateMessage();
  
      // se chamar .save para any objeto do tipo Message, então retorne o objeto criado
      when(messageRepository.save(any(Message.class))).thenReturn(message);
      
      // o mockito irá ser acionado neste step
      Message savedMessage = messageRepository.save(message);
  
      assertThat(savedMessage)
          .isInstanceOf(Message.class)
          .isNotNull()
          .isEqualTo(message);
      verify(messageRepository, times(1)).save(any(Message.class));
    }
  }
  ```

* Para o `findById`:

  ```java
  @Test
  void mustFindMessage() {
    UUID id = UUID.randomUUID();
    Message message = generateMessage();
    message.setUuid(id);
  
    when(messageRepository.findById(id)).thenReturn(Optional.of(message));
  
    Optional<Message> messageOptional = messageRepository.findById(id);
  
    verify(messageRepository, times(1)).findById(id);
    
    assertThat(messageOptional).isPresent().containsSame(message);
    messageOptional.ifPresent(savedMessage -> {
      assertThat(savedMessage.getUuid()).isEqualTo(id);
      assertThat(savedMessage.getMessage()).isEqualTo(message.getMessage());
    });
  }
  ```




### Service

Para testar a camada Service, devemos:

* Mockar a Repository
* Criar um `AutoCloseable` + setup + tearDown
* Quando o método da service for chamado, devemos **antes mockar o comportamento da repository**;

```java
class PostServiceTest {

  private PostService postService;

  @Mock
  private PostRepository postRepository;
  AutoCloseable openMocks;

  @BeforeEach
  void setup() {
    openMocks = MockitoAnnotations.openMocks(this);
    postService = new PostService(postRepository);
  }

  @AfterEach
  void tearDown() throws Exception {
    openMocks.close();
  }

  private Post generatePosts() {
    return Post.builder()
        .uuid(UUID.randomUUID())
        .user("user 1")
        .message("posts is 123")
        .build();
  }

  @Test
  void mustSavePost() {
    Post postCreated = generatePosts();

    when(postRepository.save(any(Post.class))).thenReturn(postCreated);

    Post savedPost = postService.savePost(postCreated);
    assertThat(savedPost).isInstanceOf(Post.class).isNotNull();
    assertThat(savedPost.getMessage()).isEqualTo("posts is 123");
  }

 	@Test
  void mustFindPost() {
    UUID id = UUID.randomUUID();
    Post post = generatePosts();
    post.setUuid(id);

    when(postRepository.findById(id)).thenReturn(Optional.of(post));
    Post postFound = postService.findPostById(id);

    assertThat(postFound).isInstanceOf(Post.class).isNotNull().isEqualTo(post);
    assertThat(postFound.getMessage()).isEqualTo("posts is 123");
    verify(postRepository, times(1)).findById(any(UUID.class));
  }
  
  @Test
  void mustThrowExceptionIfPostIsNotFound() {

    when(postRepository.findById(any(UUID.class))).thenReturn(Optional.empty());

    assertThatThrownBy(() -> postService.findPostById(UUID.randomUUID()))
      .isInstanceOf(RuntimeException.class)
      .hasMessageContaining("UUID not found");
    
    verify(postRepository, times(1)).findById(any(UUID.class));
  }
  
  @Test
  void mustUpdatePostMessage() {
    UUID uuid = UUID.randomUUID();
    String newMessage = "message updated";
    Post oldPost = generatePosts();
    oldPost.setUuid(uuid);

    when(postRepository.findById(uuid)).thenReturn(Optional.of(oldPost));
    when(postRepository.save(any(Post.class))).thenAnswer(i -> i.getArgument(0));

    Post postUpdated = postService.updatePostMessage(uuid, newMessage);
    assertThat(postUpdated).isInstanceOf(Post.class).isNotNull();
    assertThat(postUpdated.getMessage()).isEqualTo(newMessage);
    verify(postRepository, times(1)).findById(any(UUID.class));
    verify(postRepository, times(1)).save(any(Post.class));
  }
  
  @Test
  void devePermitirApagarMensagem() {
    var id = UUID.fromString("51fa607a-1e61-11ee-be56-0242ac120002");
    var mensagem = MensagemHelper.gerarMensagem();
    mensagem.setId(id);
    when(mensagemRepository.findById(id))
        .thenReturn(Optional.of(mensagem));
    doNothing()
        .when(mensagemRepository).deleteById(id);

    var resultado = mensagemService.apagarMensagem(id);

    assertThat(resultado).isTrue();
    verify(mensagemRepository, times(1)).findById(any(UUID.class));
    verify(mensagemRepository, times(1)).delete(any(Mensagem.class));
  }
  
}
```



## Teste Integrado

### Repository

O Teste integrado para **repository** funciona **como** se estivessemos criando **um** ***Service***, mas precisamos das anotações abaixo na classe de test:

* necessário ter um `application-test.yaml`

```java
@SpringBootTest
@AutoConfigureTestDatabase
@ActiveProfiles("test")
@Transactional
// IT stands for Integrated Test
class MessageRepositoryIT {}
```

Ao invés de usarmos o Mock, iremos usar o próprio `@Autowired`:

```java
@SpringBootTest
@AutoConfigureTestDatabase
@ActiveProfiles("test")
@Transactional
class MensagemRepositoryIT {

  @Autowired
  private MensagemRepository mensagemRepository;

  @Test
  void devePermitirCriarTabela() {
    long totalTabelasCriada = mensagemRepository.count();
    assertThat(totalTabelasCriada).isNotNegative();
  }
}
```

Dessa forma ficamos com um cenário parecido com o do Service:

```java
private Post generatePosts() {
  return Post.builder()
      .uuid(UUID.randomUUID())
      .user("user 1")
      .message("posts is 123")
      .build();
}

private Post savePost(Post post) {
  return postRepository.save(post);
}

@Test
void mustSavePost() {
  UUID randomUUID = UUID.randomUUID();
  Post post = generatePosts();
  post.setUuid(randomUUID);
  Post savedPost = savePost(post);

  long count = postRepository.count();
  assertThat(count).isPositive();

  assertThat(savedPost).isInstanceOf(Post.class).isNotNull();
  assertThat(savedPost.getUser()).isEqualTo("user 1");
  assertThat(savedPost.getMessage()).isEqualTo("posts is 123");
}

@Test
void mustFindPost() {
  UUID randomUUID = UUID.randomUUID();
  Post postGenerated = generatePosts();
  postGenerated.setUuid(randomUUID);

  Optional<Post> postOpt = postRepository.findById(randomUUID);

  assertThat(postOpt).isPresent();

  postOpt.ifPresent(post -> {
    assertThat(post.getUuid()).isEqualTo(randomUUID);
    assertThat(post).isInstanceOf(Post.class).isNotNull();
    assertThat(post.getUser()).isEqualTo("user 1");
    assertThat(post.getMessage()).isEqualTo("posts is 123");
  });
}
```



### Service

```java
@SpringBootTest
@AutoConfigureTestDatabase
@ActiveProfiles("test")
@Transactional
class MensagemServiceIT {

  @Autowired
  private MensagemRepository mensagemRepository;

  @Autowired
  private MensagemService mensagemService;

  @Test
  void devePermitirRegistrarMensagem() {
    var mensagem = MensagemHelper.gerarMensagem();

    var mensagemArmazenada = mensagemService.criarMensagem(mensagem);

    assertThat(mensagemArmazenada)
        .isNotNull()
        .isInstanceOf(Mensagem.class);
    assertThat(mensagemArmazenada.getId())
        .isNotNull();
    assertThat(mensagemArmazenada.getUsuario())
        .isNotNull()
        .isNotEmpty()
        .isEqualTo(mensagem.getUsuario());
    assertThat(mensagemArmazenada.getConteudo())
        .isNotNull()
        .isNotEmpty()
        .isEqualTo(mensagem.getConteudo());
  }

  @Test
  void devePermitirBuscarMensagem() {
    var mensagem = MensagemHelper.registrarMensagem(mensagemRepository);

    var mensagemObtidaOptional = mensagemRepository.findById(mensagem.getId());

    assertThat(mensagemObtidaOptional)
        .isPresent()
        .containsSame(mensagem);
    mensagemObtidaOptional.ifPresent(mensagemObtida -> {
      assertThat(mensagemObtida.getId())
          .isEqualTo(mensagem.getId());
      assertThat(mensagemObtida.getUsuario())
          .isEqualTo(mensagem.getUsuario());
      assertThat(mensagemObtida.getConteudo())
          .isEqualTo(mensagem.getConteudo());
      assertThat(mensagemObtida.getDataCriacao())
          .isEqualTo(mensagem.getDataCriacao());
    });
  }

  @Test
  void deveGerarExcecao_QuandoBuscarMensagem_IdNaoExistente() {
    var id = UUID.fromString("50537a52-1ab2-11ee-be56-0242ac120002");

    assertThatThrownBy(() -> mensagemService.buscarMensagem(id))
        .isInstanceOf(MensagemNotFoundException.class)
        .hasMessage("mensagem não encontrada");
  }

  @Test
  void devePermirirAlterarMensagem() {
    var mensagemOriginal = MensagemHelper.registrarMensagem(mensagemRepository);
    var mensagemModificada = mensagemOriginal.toBuilder().build();
    mensagemModificada.setConteudo("abcd");

    var mensagemObtida = mensagemService.alterarMensagem(mensagemOriginal.getId(),
        mensagemModificada);

    assertThat(mensagemObtida)
        .isInstanceOf(Mensagem.class)
        .isNotNull();
    assertThat(mensagemObtida.getId())
        .isEqualTo(mensagemModificada.getId());
    assertThat(mensagemObtida.getUsuario())
        .isEqualTo(mensagemModificada.getUsuario());
    assertThat(mensagemObtida.getConteudo())
        .isEqualTo(mensagemModificada.getConteudo());
  }

  @Test
  void deveGerarExcecao_QuandoAlterarMensagem_IdNaoCoincide() {
    var id = UUID.fromString("5f789b39-4295-42c1-a65b-cfca5b987db2");
    var mensagemNova = MensagemHelper.gerarMensagemCompleta();

    assertThatThrownBy(
        () -> mensagemService.alterarMensagem(id, mensagemNova))
        .isInstanceOf(MensagemNotFoundException.class)
        .hasMessage("mensagem não apresenta o ID correto");
  }

  @Test
  void devePermitirApagarMensagem() {
    var mensagemRegistrada = MensagemHelper.registrarMensagem(mensagemRepository);
    var resultado = mensagemService.apagarMensagem(mensagemRegistrada.getId());
    assertThat(resultado).isTrue();
  }

  @Test
  void devePermitirIncrementarGostei() {
    var mensagemRegistrada = MensagemHelper.registrarMensagem(mensagemRepository);

    var mensagemRecebida = mensagemService.incrementarGostei(mensagemRegistrada.getId());

    assertThat(mensagemRecebida.getGostei()).isEqualTo(1);
  }

  @Test
  void devePermitirListarMensagens() {
    Page<Mensagem> mensagens = mensagemService.listarMensagens(Pageable.unpaged());

    assertThat(mensagens).hasSize(5);
    assertThat(mensagens.getContent())
        .asList()
        .allSatisfy(mensagem -> {
          assertThat(mensagem).isNotNull();
          assertThat(mensagem).isInstanceOf(Mensagem.class);
        });
  }

  @Test
  @Sql(scripts = {"/clean.sql"}, executionPhase = Sql.ExecutionPhase.BEFORE_TEST_METHOD)
  void devePermitirListarTodasAsMensagens_QuandoNaoExisteRegistro() {
    Page<Mensagem> mensagens = mensagemService.listarMensagens(Pageable.unpaged());
    assertThat(mensagens).isEmpty();
  }

}
```



## Nested

Uma forma de organizar os testes é utilizando `@Nested`:

```java
  @Nested
  class RegistrarMensagem {

    @Test
    void devePermitirRegistrarMensagem() {
      var mensagem = MensagemHelper.gerarMensagem();
      when(mensagemRepository.save(any(Mensagem.class)))
          .thenAnswer(i -> i.getArgument(0));

      var mensagemArmazenada = mensagemService.criarMensagem(mensagem);

      assertThat(mensagemArmazenada)
          .isInstanceOf(Mensagem.class)
          .isNotNull();
      assertThat(mensagemArmazenada.getUsuario())
          .isEqualTo(mensagem.getUsuario());
      assertThat(mensagemArmazenada.getId())
          .isNotNull();
      assertThat(mensagemArmazenada.getConteudo())
          .isEqualTo(mensagem.getConteudo());
      verify(mensagemRepository, times(1)).save(mensagem);
    }
  }
```

Dessa forma, quando formos executar o código estará separado por blocos



## MockMVC / Controller

Para realizar o test do Controller, precisamos do **MockMVC**

### SetUp inicial

```java
import org.springframework.test.web.servlet.MockMvc;

class MensagemControllerTest {	
	// responsável por simular a controller
  private MockMvc mockMvc;

  @Mock
  private MensagemService mensagemService;

  AutoCloseable openMocks;

  @BeforeEach
  void setUp() {
    openMocks = MockitoAnnotations.openMocks(this);
    MensagemController mensagemController = new MensagemController(mensagemService);
    mockMvc = MockMvcBuilders.standaloneSetup(mensagemController).build();
  }

  @AfterEach
  void tearDown() throws Exception {
    openMocks.close();
  }
}
```



### Testando um POST

Para testar um método POST, iremos utilizar do **`mockMvc.perform(post("/yourPath"))`**!

* Para validar a mensagem usamos o **`andExpect(status().isCreated())`**

```java
@Test
void devePermitirRegistrarMensagem() throws Exception {
  var mensagemRequest = MensagemHelper.gerarMensagemRequest();
  when(mensagemService.criarMensagem(any(Mensagem.class))).thenAnswer(i -> i.getArgument(0));

  mockMvc.perform(post("/mensagens")
      .contentType(MediaType.APPLICATION_JSON)
      .content(asJsonString(mensagemRequest)))
      .andExpect(status().isCreated());

  verify(mensagemService, times(1))
      .criarMensagem(any(Mensagem.class));
}

public static String asJsonString(final Object obj) {
    try {
    return new ObjectMapper().writeValueAsString(obj);
  } catch (Exception e) {
    throw new RuntimeException(e);
  }
}
```



### GET - jsonPath

Quando rodamos um GET, podemos validar o conteúdo que foi retornado como resposta, usando **jsonPath** + **`andExpect`**

* **`mockMvc.perform(get("/yourPath"))`**!
* **`andExpect(status().isOk())`**

```java
@Test
void devePermitirBuscarMensagem() throws Exception {
  var id = UUID.fromString("259bdc02-1ab5-11ee-be56-0242ac120002");
  var mensagem = MensagemHelper.gerarMensagem();
  mensagem.setId(id);
  mensagem.setDataCriacao(LocalDateTime.now());

  when(mensagemService.buscarMensagem(any(UUID.class))).thenReturn(mensagem);

  mockMvc.perform(get("/mensagens/{id}", id)
      .contentType(MediaType.APPLICATION_JSON))
      .andExpect(status().isOk())
      .andExpect(jsonPath("$.id").value(mensagem.getId().toString()))
      .andExpect(jsonPath("$.conteudo").value(mensagem.getConteudo()))
      .andExpect(jsonPath("$.usuario").value(mensagem.getUsuario()))
      .andExpect(jsonPath("$.dataCriacao").exists())
      .andExpect(jsonPath("$.gostei").exists());
  verify(mensagemService, times(1)).buscarMensagem(any(UUID.class));
}
```



### Exception - print / content

Se quiseremos ter mais detalhes do que o mockMvc está fazendo podemos usar:

* **`.andDo(print())`**

```java
@Test
void deveGerarExcecao_QuandoBuscarMensagem_IdNaoExistente()
    throws Exception {
  var id = UUID.fromString("259bdc02-1ab5-11ee-be56-0242ac120002");

  when(mensagemService.buscarMensagem(any(UUID.class)))
      .thenThrow(new MensagemNotFoundException("mensagem não encontrada"));

  mockMvc.perform(get("/mensagens/{id}", id)
      .contentType(MediaType.APPLICATION_JSON))
    	.andDo(print())
      .andExpect(status().isNotFound());
		  .andExpect(content().string("mensagem não encontrada"));
  verify(mensagemService, times(1))
      .buscarMensagem(any(UUID.class));
}
```



### GET - Parameters

Como testar rotas com parâmetros? 

* **`param("yourParam", "paramValue")`**

```java
@Test
void devePermitirListarMensagens() throws Exception {
  var mensagem = MensagemHelper.gerarMensagemCompleta();
  Page<Mensagem> page = new PageImpl<>(Collections.singletonList(
      mensagem));
  when(mensagemService.listarMensagens(any(Pageable.class)))
      .thenReturn(page);
  mockMvc.perform(get("/mensagens")
             .param("page", 1)
             .param("size", 10)
      .contentType(MediaType.APPLICATION_JSON))
      .andExpect(status().isOk())
      .andExpect(jsonPath("$.content[0].id").value(mensagem.getId().toString()))
      .andExpect(jsonPath("$.content[0].conteudo").value(mensagem.getConteudo()))
      .andExpect(jsonPath("$.content[0].usuario").value(mensagem.getUsuario()))
      .andExpect(jsonPath("$.content[0].dataCriacao").exists())
      .andExpect(jsonPath("$.content[0].gostei").exists());
  verify(mensagemService, times(1))
      .listarMensagens(any(Pageable.class));
}

@Test
void devePermitirListarMensagens_QuandoReceberParametrosInvalidos()
    throws Exception {
  Page<Mensagem> page = new PageImpl<>(Collections.emptyList());
  when(mensagemService.listarMensagens(any(Pageable.class)))
      .thenReturn(page);
  mockMvc.perform(get("/mensagens?page=2&ping=pong")
      .contentType(MediaType.APPLICATION_JSON))
      .andExpect(status().isOk())
      .andExpect(jsonPath("$.content").isArray())
      .andExpect(jsonPath("$.content", empty()))
      .andExpect(jsonPath("$.content", hasSize(0)));
  verify(mensagemService, times(1)).listarMensagens(any(Pageable.class));
}
```



## Rest-Assured - Controller Test Integrados

Para fazer os testes integrados da Controller, precisamos utilizar o ***Rest Asured***

```xml
<dependency>
    <groupId>io.rest-assured</groupId>
    <artifactId>spring-mock-mvc</artifactId>
    <version>5.3.0</version>
    <scope>test</scope>
</dependency>
<dependency>
    <groupId>io.rest-assured</groupId>
    <artifactId>json-schema-validator</artifactId>
    <version>5.3.1</version>
    <scope>test</scope>
</dependency>
<dependency>
    <groupId>io.rest-assured</groupId>
    <artifactId>rest-assured</artifactId>
    <version>5.3.0</version>
    <scope>test</scope>
    <exclusions>
        <exclusion>
            <groupId>org.codehaus.groovy</groupId>
            <artifactId>groovy</artifactId>
        </exclusion>
        <exclusion>
            <groupId>org.codehaus.groovy</groupId>
            <artifactId>groovy-xml</artifactId>
        </exclusion>
    </exclusions>
</dependency>
```

### SetUp

As classes com RestAssured precisam seguir o padrão:
```java
@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)
@AutoConfigureTestDatabase
@ActiveProfiles("test")
@Transactional
class MensagemControllerIT {

  @LocalServerPort
  private int port;

  @BeforeEach
  public void setup() {
    RestAssured.port = port;
  }
}
```



### Post

Rest Assured irá seguir o fluxo:

* `given`
* `when`
* `then`

```java
import static io.restassured.RestAssured.given;
import static io.restassured.module.jsv.JsonSchemaValidator.matchesJsonSchemaInClasspath;
import static org.hamcrest.Matchers.equalTo;
import static org.hamcrest.Matchers.hasKey;
import static org.hamcrest.Matchers.notNullValue;
import static org.hamcrest.Matchers.startsWith;


@Test
void devePermitirRegistrarMensagem() {
  var mensagemRequest = MensagemHelper.gerarMensagemRequest();

  given()
      .contentType(MediaType.APPLICATION_JSON_VALUE)
      .body(mensagemRequest)
	.when()
      .post("/mensagens")
	.then()
      .statusCode(HttpStatus.CREATED.value())
      .body("$", hasKey("id"))
      .body("$", hasKey("usuario"))
      .body("$", hasKey("conteudo"))
      .body("$", hasKey("dataCriacao"))
      .body("$", hasKey("gostei"))
      .body("usuario", equalTo(mensagemRequest.getUsuario()))
      .body("conteudo", equalTo(mensagemRequest.getConteudo()));
}
```



### Schema Validator

Validar campo a campo do objeto versus o que está no banco de dados pode ser trabalhoso, para isso **rest-assured** possui o **`json-schema-validator`**

* Necessário criar um json com o schema na folder `resources/schemas`

  ```json
  {
    "$schema": "http://json-schema.org/draft-06/schema#",
    "title": "Mensagem Response",
    "type": "object",
    "additionalProperties": false,
    "properties": {
      "id": {
        "type": "string",
        "format": "uuid"
      },
      "usuario": {
        "type": "string"
      },
      "conteudo": {
        "type": "string"
      },
      "dataCriacao": {
        "type": "string"
      },
      "dataAlteracao": {
        "type": "string"
      },
      "gostei": {
        "type": "integer"
      }
    },
    "required": [
      "id",
      "usuario",
      "conteudo",
      "dataCriacao",
      "gostei"
    ]
  }
  ```

Quando for testar, irá referenciar o JSON:

```java
@Test
void devePermitirRegistrarMensagem_ValidarSchema() {
  var mensagemRequest = MensagemHelper.gerarMensagemRequest();

 	given()
      .header("Content-Type", "application/json")
      .body(mensagemRequest)
	.when()
      .post("/mensagens")
	.then()
      .statusCode(HttpStatus.CREATED.value())
      .header("Content-Type", notNullValue())
      .header("Content-Type", startsWith("application/json"))
      .body(matchesJsonSchemaInClasspath("./schemas/MensagemResponseSchema.json"));
}
```



## Maven Profiles

Para executar os testes via CLI, temos:

```bash
mvn test
```


Mas se quiseremos executar os testes integrados separados aos testes unitários, podemos configurar o `pom.xml`:

```xml
<profiles>
    <profile>
        <id>integration-test</id>
        <build>
            <plugins>
                <plugin>
                    <groupId>org.apache.maven.plugins</groupId>
                    <artifactId>maven-surefire-plugin</artifactId>
                    <version>3.1.2</version>
                    <configuration>
                        <includes combine.self="override">
                            <include>**/*IT.java</include>
                        </includes>
                        <excludes combine.self="override">
                            <exclude>**/*Test.java</exclude>
                        </excludes>
                    </configuration>
                </plugin>
            </plugins>
        </build>
    </profile>
</profiles>
```

Dessa forma podemos executar:
```bash
mvn test -P integration-test
```



## Allure Report

O Allure Report gera reports de cada classe de Test criada

<img src="./imageResource/allurerport.png" alt="allurerport" style="zoom:50%;" />

### SetUp

1. Adicionar dependências

   ```xml
    <dependency>
         <groupId>io.qameta.allure</groupId>
         <artifactId>allure-junit5</artifactId>
         <version>2.23.0</version>
         <scope>test</scope>
     </dependency>
     <dependency>
         <groupId>io.qameta.allure</groupId>
         <artifactId>allure-rest-assured</artifactId>
         <version>2.23.0</version>
     </dependency>
   ```

2. Alterar o `plugin` do `maven-surefire-plugin`, adicionando `properties` + `systemPropertyVariables`

   ```xml
   <plugin>
       <groupId>org.apache.maven.plugins</groupId>
       <artifactId>maven-surefire-plugin</artifactId>
       <version>3.1.2</version>
       <configuration>
           <excludes>
               <exclude>**/bdd/**</exclude>
           </excludes>
           <properties>
               <configurationParameters>
                   junit.jupiter.displayname.generator.default.remove-parent=true
               </configurationParameters>
           </properties>
           <systemPropertyVariables>
               <junit.jupiter.extensions.autodetection.enabled>true</junit.jupiter.extensions.autodetection.enabled>
               <allure.results.directory>${project.build.directory}/allure-results</allure.results.directory>
           </systemPropertyVariables>
       </configuration>
       <dependencies>
           <dependency>
               <groupId>org.aspectj</groupId>
               <artifactId>aspectjweaver</artifactId>
               <version>${aspectj.version}</version>
           </dependency>
       </dependencies>
   </plugin>
   ```

3. Criar o `allure.properties` dentro de `resources`:

   ```properties
   allure.results.directory=target/allure-results
   ```

4. Ao rodar `mvn test` irá ser gerado uma folder dentro de targets, chamada `allure-results` - para exibir o relatório precisaremos instalar globalmante o `allure`

   ```sh
   npm install -g allure
   ```

5. Executar o `allure serve`

   ```sh
   allure serve target/allure-results
   ```

6. Dentro de cada classe de integração, precisaremos por no `setup` do `@BeforeEach` o `RestAssured.enableLogging`:

   ```java
   @BeforeEach
   public void setup() {
     RestAssured.port = port;
     RestAssured.enableLoggingOfRequestAndResponseIfValidationFails();
   }
   ```

7. Colocar um filter para cada método que queira detalhes do `Allure Report`:

   ```java
   @Test
   void devePermitirRegistrarMensagem() {
     var mensagemRequest = MensagemHelper.gerarMensagemRequest();
   
     given()
       	// filter para exibir no Allure Report
         .filter(new AllureRestAssured())
         .contentType(MediaType.APPLICATION_JSON_VALUE)
         .body(mensagemRequest)
     .when()
         .post("/mensagens")
     .then()
         .statusCode(HttpStatus.CREATED.value())
         .body("$", hasKey("id"))
         .body("$", hasKey("usuario"))
         .body("$", hasKey("conteudo"))
         .body("$", hasKey("dataCriacao"))
         .body("$", hasKey("gostei"))
         .body("usuario", equalTo(mensagemRequest.getUsuario()))
         .body("conteudo", equalTo(mensagemRequest.getConteudo()));
   }
   ```

   

## Gatling - Test Performance

Com o **`Gatling`** conseguimos simular diferentes usuários realizando ações dentro de nossa aplicação, e também especificar qual ação o usuário estárá fazendo por X tempo.

### Dependências

```xml
<dependency>
    <groupId>io.gatling</groupId>
    <artifactId>gatling-app</artifactId>
    <version>3.9.5</version>
</dependency>
<dependency>
    <groupId>io.gatling.highcharts</groupId>
    <artifactId>gatling-charts-highcharts</artifactId>
    <version>3.9.5</version>
    <scope>test</scope>
</dependency>
```

### Maven Profile

Para facilitar e diferenciar os testes, criaremos um profile para testes de performance

```xml
<profile>
    <id>performance-test</id>
    <build>
        <plugins>
            <plugin>
                <groupId>io.gatling</groupId>
                <artifactId>gatling-maven-plugin</artifactId>
                <version>4.3.7</version>
                <configuration>
                  	<!-- Package que estará os testes -->
                    <simulationClass>org.example.performance.ApiPerformanceSimulation</simulationClass>
                </configuration>
            </plugin>
        </plugins>
    </build>
</profile>
```



### Simulation

Para simular chamadas, iremos criar uma classe de test que irá **extender `Simulation`**:

```java
public class ApiPerformanceSimulation extends Simulation {

    private final HttpProtocolBuilder httpProtocol = http
            .baseUrl("http://localhost:8080")
            .header("Content-Type", "application/json");
}
```

A partir do `HttpProtocolBuilder` iremos criar **cada ação** que o usuário irá performar:
```java
private final HttpProtocolBuilder httpProtocol = http
        .baseUrl("http://localhost:8080")
        .header("Content-Type", "application/json");

ActionBuilder adicinarMensagemRequest = http("adicionar mensagem")
        .post("/mensagens")
        .body(StringBody("{ \"usuario\": \"user\", \"conteudo\": \"demo\" }"))
        .check(status().is(201))
        .check(jsonPath("$.id").saveAs("mensagemId"));

ActionBuilder buscarMensagemRequest = http("buscar mensagem")
        .get("/mensagens/#{mensagemId}")
        .check(status().is(200));

ActionBuilder listarMensagemRequest = http("listar mensagens")
        .get("/mensagens")
        .queryParam("page", "0")
        .queryParam("size", "10")
        .check(status().is(200));
```

Criar o `scenarios` para cada `action`:

```java
ScenarioBuilder cenarioAdicionarMensagem = scenario("Adicionar mensagem")
        .exec(adicinarMensagemRequest);

ScenarioBuilder cenarioAdicionarBuscarMensagem = scenario("Adicionar e Buscar mensagem")
        .exec(adicinarMensagemRequest)
        .exec(buscarMensagemRequest);

ScenarioBuilder cenarioListarMensagem = scenario("Listar mensagens")
        .exec(listarMensagemRequest);
```



Criar um **setUp de usuário** para cada **scenario**:

```java
{
  setUp(
    cenarioAdicionarMensagem.injectOpen(
          rampUsersPerSec(1)
                  .to(10)
                  .during(Duration.ofSeconds(10)),
          constantUsersPerSec(10)
                  .during(Duration.ofSeconds(60)),
          rampUsersPerSec(10)
                  .to(1)
                  .during(Duration.ofSeconds(10))),
		cenarioAdicionarBuscarMensagem.injectOpen(
          rampUsersPerSec(1)
                  .to(30)
                  .during(Duration.ofSeconds(10)),
          constantUsersPerSec(30)
                  .during(Duration.ofSeconds(60)),
          rampUsersPerSec(30)
                  .to(1)
                  .during(Duration.ofSeconds(10))),
    cenarioListarMensagem.injectOpen(
          rampUsersPerSec(1)
                  .to(100)
                  .during(Duration.ofSeconds(10)),
          constantUsersPerSec(100)
                  .during(Duration.ofSeconds(60)),
          rampUsersPerSec(100)
                  .to(1)
                  .during(Duration.ofSeconds(10))))
    )
    .protocols(httpProtocol)
                .assertions(
                        global().responseTime().max().lt(50),
                        global().failedRequests().count().is(0L)
  								);
}
```



Para executar o teste de performance, **precisamos da aplicação rodando!** e então iremos rodar com o **`gatling`**

```shell
mvn gatling:test -P performance-test
```

Para visualizar o report do gatling, vamos em:

```
open target/gatling/performancessimulation-xxxxx/index.html
```



## K6 - Test Performance

Existe uma forma mais simples de realizar testes, **sem escrever código**, mas 'bombardeando' com HTTP requests a aplicação

- Criei `/test-carga/index.js`

```javascript
import http from 'k6/http';
import { sleep } from 'k6';

export const options = {
  discardResponseBodies: true,
  scenarios: {
    contacts: {
      executor: 'per-vu-iterations',
      vus: 10,
      iterations: 20,
      maxDuration: '30s',
    },
  },
};

export default function () {
  http.get('http://localhost:9080/myEndPoint');
  sleep(0.5);
}
```

* Execute com `k6 run index.js`



# Fase 4 - Spring Webflux

## Porque programação reativa?

* Precisamos de sistemas:
  * Rápidos
  * Escaláveis
  * Responsivos

O modo tradicional, chamado de **bloqueante**, espera que uma ação por vez seja executada:

<img src="/Users/igorgomesromerovilela/Development/NotesInGeneral/Java/graduate/imageResource/reqBloqueante.png" alt="reqBloqueante" style="zoom:50%;" />

A **idéia de uma programação** reativa é **liberar a thread** para que ela faça outra task enquanto aguarda o retorno do banco de dados por exemplo, e para isso, surgiu o **WebFlux**, para ligar com **modo async e não bloqueante**

### Exemplo Bloqueante

```java
@RestController
public class ExemploController {
  private final ExemploService exemploService;

  @Autowired
  public ExemploController(ExemploService exemploService) {
    this.exemploService = exemploService;
  }

  @GetMapping("/exemplo/{id}")
  public ResponseEntity<Exemplo> getExemplo(@PathVariable Long id) {
    // Chamada bloqueante para o serviço que retorna o resultado direto
    Exemplo resultado = exemploService.buscarPorId(id);

    // Retorna o resultado como resposta HTTP
    return ResponseEntity.ok(resultado);
  }
}


@Service
public class ExemploService {
  private final ExemploRepository exemploRepository;

  @Autowired
  public ExemploService(ExemploRepository exemploRepository) {
    this.exemploRepository = exemploRepository;
  }

  public Exemplo buscarPorId(Long id) {
    // Operação de consulta bloqueante que retorna o resultado direto
    return exemploRepository.findById(id).orElse(null);
  }
}

public interface ExemploRepository extends CrudRepository<Exemplo, Long> {
    // Métodos de consulta personalizados, se necessário
}
```

### Exemplo não bloqueante

Com uso do:

* `Mono` -> retornamos um único objeto
* `Flux` -> retornamos uma Lista

```java
@RestController
public class ExemploController {
  
  @Autowired
  private ExemploService exemploService;

  @GetMapping("/exemplo/{id}")
  public Mono<ResponseEntity<Exemplo>> getExemplo(@PathVariable Long id) {
    // Chamada não bloqueante para o serviço que retorna um Mono
    Mono<Exemplo> resultadoMono = exemploService.buscarPorIdReativo(id);

    // Retorna um Mono que irá mapear o resultado para uma resposta HTTP
    return resultadoMono.map(ResponseEntity::ok);
  }
}

@Service
public class ExemploService {
  
  @Autowired
  private ExemploRepository exemploRepository;

  public Mono<Exemplo> buscarPorIdReativo(Long id) {
    // Operação de consulta reativa que retorna um Mono
    return exemploRepository.findById(id);
  }
}


public interface ExemploRepository extends ReactiveCrudRepository<Exemplo, Long> {
    // Métodos de consulta personalizados, se necessário
}
```



## Dependências / DBs / Obs.

**Por padrão o servidor de aplicação do spring para programação reativa é o NETTY**

Para iniciar com spring webflux precisamos:

```xml
<dependency>
  <groupId>org.springframework.boot</groupId>
  <artifactId>spring-boot-starter-webflux</artifactId>
</dependency>
<dependency>
  <groupId>io.projectreactor</groupId>
  <artifactId>reactor-test</artifactId>
  <scope>test</scope>
</dependency>
```

Alguns bancos de dados são apropriados para trabalhar com banco de dados reativo:

* MongoDB
* Kassandra

```xml
<dependency>
  <groupId>org.springframework.boot</groupId>
  <artifactId>spring-boot-starter-data-mongodb-reactive</artifactId>
</dependency>
<dependency>
  <groupId>de.flapdoodle.embed</groupId>
  <artifactId>de.flapdoodle.embed.mongo</artifactId>
  <scope>test</scope>
</dependency>
```

* DB2 não fornece suporte nativo para trabalhar com programação reativa, porém existem adaptadores:
  * **Spring Data R2DBC (Reactive Relational Database Connectivity)**

```xml
<dependencies>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-data-jpa</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-data-r2dbc</artifactId>
    </dependency>
    <dependency>
        <groupId>com.ibm.db2</groupId>
        <artifactId>db2jcc4</artifactId>
        <version>versao_do_driver</version>
    </dependency>
</dependencies>
```



## Stream de Eventos

Para melhorar ainda mais a forma reativa, ao invés de utilizarmos **JSON** como retorno, podemos usar **Stream de eventos**

```java
@GetMapping(value = "/events", produces = MediaType.TEXT_EVENT_STREAM_VALUE)
```

Como simples exemplos, temos:
```java
@GetMapping(value = "/events", produces = MediaType.TEXT_EVENT_STREAM_VALUE)
public Flux<Tuple2<Long, Carteira>> streamTest() {
  Flux<Long> interval = Flux.interval(Duration.ofSeconds(10));
  Flux<Carteira> allCarteiras = carteiraService.findAll();
  return Flux.zip(interval, allCarteiras);
}
```

