# Pós - Arquitetura e Desenvolvimento Java

Matrícula: **RM430091** (vi96)

Email: rm430091@fiap.com.br **(DtNasc#080396)**



## Lives

* Canivete Suiço? **Quais ferramentas escolher para o dia a dia de um backend**. :heavy_check_mark:
  *  https://zoom.us/rec/share/yyeoHiEZ6clMt3Qi4to4hJwRLxnJOkVdpBDQmQECiW5W8NCELYBLLsR7ex1t59lz.CJ0xaB8vht5RSf3A  
  * `7h3\*Xm@N`
* SOAP vs REST vs gRPC: **Qual devo usar para criar a API** :heavy_check_mark:
  * https://zoom.us/rec/share/tQEJjH2DdiQ0IxkkOg_rEv7SPNdKzQegzsauiQXj5VsxtxluTD7s6lSYQcw2OX59.eElEMw44ytxmQIAI  
  * `!R2B4H%$`
* LIVE EXTRA - Projeto Coda Comigo -  **Utilização do Lombok/Validação com Bean Validation** :heavy_check_mark:
  * https://zoom.us/rec/share/lhQpqQa31owzO6Qta7jZxUQAci7FcpoomeSa6iH7GMm40rMgPfLGrpEjCKVTv3D3.dFGDEikLo7AjRaqk?startTime=1686783690000
  * `$=AZ6&.H`
*  LIVE EXTRA - Projeto Coda Comigo - **DTO/Records** :heavy_check_mark:
  * https://zoom.us/rec/share/u0cY9y-15Qfm7E_iqotPxzdG5Q73fjwWEeHMa15W0LjZv9LKqDlPIEL3mpXXuble.82l50Sh6L0hFEKDw?startTime=1687387944000
  * `8&7%wd#O`

* LIVE EXTRA - Projeto Coda Comigo - **Testes Unitários e Validação de Beans** :heavy_check_mark:
  * https://zoom.us/rec/share/vhCyPyXU6B6TAxdHAiXIsJsQgqf3cluIjkWWBnAwfB4cOkVByDABprKLz7suL3kl.BtvHrx32KkWvbp7b 
  * `8*%SH^HE`

* Live de Persistência 1: **Introdução ao SQL e PostgresSQL** :heavy_check_mark:
  * https://zoom.us/rec/share/XO_PSbk7B6JdkGTgvP8c2JgheEntsnKkokjdb4X-dTPfYvX9P1D0TkyS-yDZfIo0.Pl_H1WY4q-VOA7dq 
  * `28cC+%x0`

* Live de Persistência 2: **Mapeamento de Entidades JDBC** :heavy_check_mark:
  * https://zoom.us/rec/share/Jr92C0GFQ_RaTXi61m4kxzPNVvPSXoFGyNOQvPJqU6vfQOvGiI3hTXdflvlexu4R.p_zpC_r38RoSjcwj 
  * `Q3.j@rqa`
* Live de Persistência 3 + 4: **Consultas com Spring JPA + Relacionamentos :heavy_check_mark:**
  * [https://zoom.us/rec/share/1rzC337hD5Xwo-CpstiaHAaNA3Ml_lieRx-9ZdgJnqmvlAY4l3JrRj4ccP6qMqHR.Iqj0gaZqqu9Dw13_](https://zoom.us/rec/share/1rzC337hD5Xwo-CpstiaHAaNA3Ml_lieRx-9ZdgJnqmvlAY4l3JrRj4ccP6qMqHR.Iqj0gaZqqu9Dw13_)
  * `=aq!B2Y9`

* Live de Persistência 5: **Relacionamentos One to One e One to Many no JPA** :heavy_check_mark:
  * https://zoom.us/rec/share/HSUMl9Jsz1cO74hl799NmphzDKgAsu6EM4Fn2ZzjDY31ppChhwnDKv8rNxkn59D_.S8DqwjyPY1J7Ld3i 
  * `g4c!dS?Z`

* Live de Persistência 6: **Introdução ao JPQL** :heavy_check_mark:
  * https://zoom.us/rec/share/dMcCbmBfJTvDED9F5QDmWijctCMPBtnAl7TiHsXxeS6A2eTqQHubMbr7AvN_Nyes.nlQ-y-TERsZKPnV3 
  * `asUpp0?3`

* Live: Dominando Deploys
  * https://zoom.us/rec/play/TwpDfRDBo3ECl3J4UFoJc2hdHHfzqYgnhgQV0ec5PkSImaeIm83kVUyD-HipTwqZ3GF1d1-kaeJWBERZ.b7JBnJoQutf1xOJW?canPlayFromShare=true&from=recording_mg&continueMode=true&iet=ufWhVy3WaurrlpCIYANb5ax-FTSSDdnlG1kkpA6QOD4.AG.Bj1-tP8zJFxVljFA9-mnrldGsUCrXfxZ9Y1i3FrzJHh7FfjSZJ-UlCyLrybNz0m_qyXRC46PIpqM5JNcM9waiQPEyhWCSX2uAwGnwWjiJ3bCfs1AuxvOE4eMSEG9kvkvBKxmQVjn5g.4TlXsoAuySS4zLN_ogqquw.CsN21ab7qbfZg2mb&componentName=rec-play&originRequestUrl=https://zoom.us/rec/share/gtYrKfGvrrSnbxHec20p2mORi-EF4wi7WMltwgCgPAlZ0ZYGhQKimp1B1t3hQTeq.dlkP-LeQ00jU0ckW?iet=ufWhVy3WaurrlpCIYANb5ax-FTSSDdnlG1kkpA6QOD4.AG.Bj1-tP8zJFxVljFA9-mnrldGsUCrXfxZ9Y1i3FrzJHh7FfjSZJ-UlCyLrybNz0m_qyXRC46PIpqM5JNcM9waiQPEyhWCSX2uAwGnwWjiJ3bCfs1AuxvOE4eMSEG9kvkvBKxmQVjn5g.4TlXsoAuySS4zLN_ogqquw.CsN21ab7qbfZg2mb
  * `8#N#wy@!`



## April 27 - Aula Inaugural 00

* Gustavo Genari - CEO FIAP
* Paulo Vieira - CEO Alura
* Adriano Almeida - COO Alura
* Andrea Paiva - Head/Diretora MBA On
* Vlad Cruz - Professor
* Cassio Oliveira - Coordenador

Curso dividido em 5 fases. No Final do curso haverá um desafio final com tudo que foi aprendido, com **hackathon**.

1. Primeiros passos com Spring
2. DDD e testes automatizados
3. Requisitos, portabilidade e qualidade de Software
4. Deploy e mensageria
5. Spring JPA e desenvolvimento seguro

Aulas:

* Cada 15 dias tem live

Testes:

* Fast Test - Questões de múltipla escolha
* Desafio - final de fase
  * E.g: Construir um app para cadastro de cliente (interface)
  * Webservice / Persistencia
* Hackathon
* Fase 5 é necessário ir presencial, marcar

Notas:

* Fast Test
* Tech Challenge
* Hackaton
* Atividade Presencial<img src="./imageResource/notas.png" alt="Screenshot 2023-04-27 at 19.58.27" style="zoom:30%;" />



**Desafio 1**

https://forms.office.com/pages/responsepage.aspx?id=4r_bEbiJSUW-EM7DZOWVUcuxE3m2i81CkgE7F-PZ4k5UMFY4RTVZR0FKTlNKN1IwRTUzMVdLREkzRi4u

* 70 questões múltipla escolha, conceito, leutura e intepretação de código
  * 1 só correta
  * Pesos diferentes
  * 20:45 - termina



# Fase 1 - First Steps w/ Spring

Projeto git: https://github.com/FIAP/PostTech_Java_AluraBank

## Aula 1 - Motivação & REST & HTTP

* HTTP são todas conexões que realizamos em um browser para acessar um site;
* Para acessar uma requisição HTTP precisamos:
  * Tipo de requisição:
    * HTTP é o tipo de requisição - HTTPS é a requisição HTTP + Protocolo SSL de criptografia;
  * Endereço da requisição:
    * Todo servidor possui um número global, que quando acessado um domínio (google) é direcionado para o número 123.456.789
* **Response**: resposta do servidor
* **Header**: Utilizado na requisição para passar mais informação, como o tipo de resposta (JSON/TEXT/XML), Token de autenticação. Todo header tem um tamanho máximo default por servidor (tomcat é 8kb).
* **APIs**: Application Programming Interface, é um mecanismo que permite que duas aplicações de linguagens distintas se comuniquem, mas para isso uma série de definições e protocólos sejam definidos nas requisições e respostas
  * Tipos de APIs:
    * **SOAP**: client e sevidor utilizam XML para trocar dados;
    * **RPC**: Remote Procedure Call - permite que um app chame procedimento de outra função;
    * **Websocket**: conexão bidrecional entre servidor e cliente, para trocarem informações (jogos e chats);
    * **REST**: Transferencia Representacional de Estado - Cliente solicita informações ao servidor, que o processa e devolve para o cliente;
      * Benefícios:
        * Integração
        * Inovação
        * Expansão
        * Facilidade de Manutenção

```bash
Resumo da aula part 1:

Professor Rodrigo Vieira e o Paulo Silveira apresentaram o funcionamento de uma comunicação HTTP.
Assim como os seres humanos conversam entre si em uma linguagem que ambos entender, assim funciona os computadores.

Um protocólo serve para ambos conversarem, onde uma:
- Requisição
- Resposta
Devem acontecer...

Por padrão quando acessamos uma página, fazemos:
- Verbo HTTP (GET)
- Endereço (https://xxxxxx.com.br) -> URL (nome único) Uniform Resource Locator
- Body + header (opcionais)

Retorno:
- Status code (200, 404, 302)
- Response

Para testar podemos fazer via cURL

curl -i -X GET https://alura.com.br
-i -> queremos detalhes
-X -> método HTTP

Algumas requisições são bloqueadas por falta de certificado
```

```bash
Resumo da aula parte 2:

GET com parâmetros pode ser feito com o curl tbm
➜  ~ curl -i -X GET "https://postman-echo.com/get?nome=igor&idade=27"
HTTP/2 200
date: Thu, 04 May 2023 01:03:20 GMT
content-type: application/json; charset=utf-8
content-length: 354
etag: W/"162-hbyVcNEljpowYSxiiK4cobBye+g"
set-cookie: sails.sid=s%3AiMVw_ReiXxsiUvrEo1R2fPfIfNBETTOC.Fq76U4YkBbBbpRWH5e3DCcocmkrEJAVz7ssXQd5Hz7E; Path=/; HttpOnly

{
  "args": {
    "nome": "igor",
    "idade": "27"
  },
  "headers": {
    "x-forwarded-proto": "https",
    "x-forwarded-port": "443",
    "host": "postman-echo.com",
    "x-amzn-trace-id": "Root=1-64530458-439776466e260d2a564c0cf4",
    "user-agent": "curl/7.87.0",
    "accept": "*/*"
  },
  "url": "https://postman-echo.com/get?nome=igor&idade=27"
}%


Para fazer POST também podemos passar parâmetros com o curl, iremos passar outros valores:
-d -> para o body
-H -> para o Header

➜  ~ curl -i -X POST https://postman-echo.com/post -H "Content-Type:application/json" -d '{"chave1":"value1","chave2":"value2"}'
HTTP/2 200
date: Thu, 04 May 2023 01:09:37 GMT
content-type: application/json; charset=utf-8
content-length: 520
etag: W/"208-s4iYVSWcMJoCJA9nf9ZLn5k6a8E"
set-cookie: sails.sid=s%3AumBo_JZDgxovCUB_XrY1-wxA0udgcuNx.Xo0kdWh1LjGmbTgtw0kLst7Dr%2B9neQJUJePBc092Gg0; Path=/; HttpOnly

{
  "args": {},
  "data": {
    "chave1": "value1",
    "chave2": "value2"
  },
  "files": {},
  "form": {},
  "headers": {
    "x-forwarded-proto": "https",
    "x-forwarded-port": "443",
    "host": "postman-echo.com",
    "x-amzn-trace-id": "Root=1-645305d1-60d7361e3061a4bf07d6cd95",
    "content-length": "37",
    "user-agent": "curl/7.87.0",
    "accept": "*/*",
    "content-type": "application/json"
  },
  "json": {
    "chave1": "value1",
    "chave2": "value2"
  },
  "url": "https://postman-echo.com/post"
}%
```

Status Codes: https://httpcats.com/



## Aula 2 - Spring

* Spring foi criado pela empresa Pivotal, como um projeto java open source
* Objeto principal era facilitar o desenvolvimento, implementando o conceito de **injeção de dependência + inversão de controle.**
  * Surgiu para substituir o então **J2EE**, que era bom para criação de aplicações.
* Spring não precisa de um **servidor de aplicação** para funcionar;
* Spring podemos criar aplicações **reativas, batchs, web apps, apps cloud, apps serveless**;



### Projetos Spring

* **Spring Boot**: forma mais rápida de criação de apps;
  * Cria apps stand-alone;
  * Internaliza servidores de aplicação como tomcat, jetty (sem precisar do war);
  * Configura automaticamente o Spring e libs terceiros
  * Sem necessidade de códigos ou xml;
* **Spring Framework:** é o core para injeção de dependencias, webapps;
* **Spring Data:** feito para lidar com banco de dados relacionais, não relacionais, cloud;
* **Spring Security:** framework para autenticação e autorização, customizável;



### Spring Boot

* Para que o Spring Boot funcione, é necessario 4 tipos de componentes:
  * **Spring Boot Starter:** Combina várias bibliotecas em uma só, sem que aja a necessidade de adicionar várias dependências. Exemplo, quando adicionamos o spring mvc, já adicionamos também o web, core, mvc e servlet API.
  * **Spring Boot CLI:** CLI é utilizado como uma linha de comando para iniciar o Spring Starter e AutoConfigurator
  * **Spring Boot AutoConfigurator:** gerencia as configurações do Spring, permitindo configurações personalizadas;
  * **Spring Boot Actuator:** Prove os endpoints e as métricas + responsável por definir que o servidor fique exposto na porta XYZ;



### Spring Initializr

* É uma ferramenta que ajuda na criação de um projeto Spring Boot - https://spring.io/projects
* Para utiliza-lo precisamos definir:
  * Maven ou Gradle
  * Java ou Kotlin
  * Versão do Spring Boot
  * Empactamento:
    * **JAR** (Java Archive) - mais usual, é um zip com as bibliotecas utilizadas no projeto, utilizada em outros projetos java;
    * **WAR** (Web Application Archive) - é um zip voltado para web, muito usado pelo antigo **Tomcat**;
  * Dependências (Spring MVC, WEB, REACTIVE, CLOUD, DATA);



### Como era sem o Spring...

A injeção de dependências foi o que tornou o Spring tão popular. Antes do Spring, era muito comum o uso de um padrão chamado **REGISTRY**, onde a idéia é criar uma classe `static` que **fabrica os objetos**.

```java
public class Registry {
  
  public static final Evento getEvento() {
    return new Evento(getEscola(), new LocalDoEvento());
  }
  
  public static final Escola getEscola() {
    return new Escola();
  }
}
```

* O Registry tende a crescer conforme mais classes são criadas;
* O Registry permite o uso Global das classes (má prática e grande problema nos apps mais antigos) - já que basta chamal-lo e teremos acesso a classe;
* Favore o **acoplamento!**
  * ***Se sua classe possui vários imports de classes diferenetes do projeto, ISSO É SINAL DE ACOPLAMENTO!***

#### @Component

Basicamente, invés de **termos o registry, o Spring veio com um simples `@Component`** para resolver a injeção das dependencias!

* @Component é anotação mais básica, que pede ao Spring ***Gerencie para mim essa classe/injete automaticamente ela***

## Aula 3 - Gerenciador de dependências

* Quando temos uma série de classes que fazem sentido entre si, podemos **considera-la do mesmo pacote!**
* O uso de biblioteca veio para validar o termo **para que recriar a roda?** Se alguém já desenvolveu determinada função, basta implementar-los ela;
* **Problema dos pacotes antigamente:** 
  * quando usamos muito e precisamos atualiza-los, como fazemos? temos que ir manualmente em cada pacote e ir atualizando cada um deles :sweat:
  * Uma biblioteca precisa de outra, que precisa de outra e assim por diante...
* Os gerenciadores de dependencia/pacotes vieram para resolver este problema.
  * **Java: Maven / Gradle**
  * Javascript: NPM / Yarn
  * .NET: NuGet
  * Python: PIP

### Maven

Desenvolvido pela **Apache**, maven através do arquivo **pom (Project Object Model)** pode configurar todas as dependências do projeto;

* Maven segue o **`CoC`** (**Convention over Configuration**) - que estipula um padrão de estrutura para cada folder, onde o maven já sabe onde procurar os files
* Os arquivos baixados pelo maven ficam dentro do diretório **`.m2`**;
* Ciclos:
  * **`mvn compile` -> Gera os . class**
  * `mvn test`
  * **`mvn package` -> Gera o Jar**
  * **`mvn install` -> Roda todos steps anteriores**
* Arquivos gerados pelo maven vão para pasta `target` do projeto;
* Se executarmos um `java -jar fileCriadoPeloMaven.jar` será iniciado o projeto;

**Pros**:

* Gerenciador Java **mais conhecido e mais antigo**;
* Maior parte dos projetos utilizam;
* Fácil de ler (XML);
* Processo de build simplificado (`man package` | `mvn install`)

**Cons:**

* Necessita instalação ( `brew install mvn`);
* Díficil de escrever (por ser XML);

### Gradle

Desenvolvido pela **Gradle**, junta as mesmas dependências do **Maven e Ivy**.

* Utilizado em **projetos Android**;
* Utiliza a linguagem **Groovy**; (ou seja precisa saber uma nova linguagem para criar o arquivo)

```groovy
apply plugin: 'java' 
apply plugin: 'eclipse' 
apply plugin: 'application' 

mainClassName = 'hello.HelloWorld' 

repositories { 
  mavenCentral() 
} 

jar { 
  archiveBaseName = 'gs-gradle' 
  archiveVersion = '0.1.0' 
}

sourceCompatibility = 1.8 
targetCompatibility = 1.8 
dependencies { 
  implementation "joda-time:joda-time:2.2" 
  testImplementation "junit:junit:4.12" 
}
```



## Aula 4 - Coesão e Acoplamento

*Um projeto precisa ser entregue, porém sempre com qualidade! Um fator determinante é a **coesão e acoplamento.*** Alguns projetos não se preocupam com a reutilização de códigos, **mas na orientação a objetos este é o tema central!**

* **Acoplamento:**
  * O quanto um **componente depende do outro** é o que define o **grau de acoplamento**.
  * **Componente depende muito de outro = Alto acoplamento; :x:**
  * **Problema:** difícil de dar manutenção, uma alteração pode ter um efeito cascata em outros componentes.
  * **Tipos:**
    * **Desenvolvimento:** Um componente depende do outro, podendo gerar um **efeito cascata**;
    * **Semântica**: Quando 2 componentes compartilham do mesmo conceito no projeto;
    * **Funcional**: Quando 2 componentes precisam executar juntos uma função;
    * **Incidental**: Quando 2 componentes estão juntos sem uma real necessidade;
    * **Operacional**: Quando um componente precisa de outro para realizar uma tarefa;
* **Coesão:**
  * Se o **acoplamento se preocupa com o externo** (relação entre 2+ componentes), a **coesão se preocupa com o interno**, ou seja, o que aquele componente X está fazendo.
  * Pensando no UNO, imagine que a carta **6 vermelha tem uma única função!** Tem uma cor + número... mas como seria se uma carta pudesse mudar de cor, número e fizesse outras coisas?
  * **Componente com muita responsabilidade = Baixa coesão;** :x:



## Aula 6 - Annotations

* No Java os primeiros ***metadados*** foram criados para preenchimento da **javadoc.** 

* A partir do JSR 175, foram introduzidas as ***annotations*** (defindas pelo **`@`**), que permitiam que metadados fossem atribuídos a métodos, classes, campos, parâmetros e etc;

* Spring faz muito o uso das annotations, como em:

  * `@RestController` -> Indica que se trata de uma classe que para uma API Rest;

  * `@RequestMapping` -> endereço da API

  * `@JsonProperty` -> Informa ao Spring que deverá ser feito um binding do parâmetro para json

    * ```java
      public class myEntity {
        
        @JsonProperty
        private String name;
        
        @JsonProperty
        private int age;
      }
      
      // { name:'igor', age: 27}

## Aula 7 - MVC

* Quando pensamos que um **projeto poderá sofrer alterações no futuro**, ou quando pensamos em **qualidade**, o padrão mais conhecido é o **MVC (Model View Controller)**.
  * **Controller**: Cuida das rotas;
  * **View**: O que é apresentado ao usuário;
  * **Model**: É o objeto, onde fica a regra de negócio;
* Criado em 1970, para projetos visuais.
* Controller recebe a requisição, chama a camada de negócio (Model) e então devolve uma View;



**MUITOS PROJETOS NÃO DIVIDEM BEM A LÓGICA DE NEGÓCIO E TECNOLOGIA**!

* Lógica de negócio **DEVE ficar na classe de domínio!**
* Lógica de tecnologia, deve ficar nas classes Services/Controllers

# Fase 1 - Criação de API Rest w/ SpringBoot

## Aula 1 - Chamando a API

* Existem algumas formas de se "chamar" uma API, o GET talvez seja o mais simples, **podemos utilizar o próprio browser!** porém não podemos utilizar os outros métodos HTTP;
  * O Chrome possui plugins para chamadas REST, como o ***Advanced Rest Client***.
* Quer fazer **via terminal? Existe o CURL!** Porém, é massivo ficar digitando os comandos...
* Softwares? Temos **Postman & Insomnia**! User friendly, quer nos permite fazer todas chamadas, salva-las em collections e etc...

## Aula 2 - Injeção de dependência

* Antes de falar sobre injeção de dependência, precisamos entender ***O quê é uma dependência?***
  * **Dependência é um objeto do qual OUTRO objeto depende!** simples assim :smiley:
* Quando de como uma dependência é utilizada, **pode ficar muito difícil dar manutenção**. Para isso foi criado a chamada ***Injeção de dependência***, que **remove o acoplamento** entre objetos/dependentes.



### Sem injeção de dependência

Dado o exemplo:

```java
public class MyService {
  
  private CalculadoraDeImpostosNacionais calculadora = new CalculadoraDeImpostosNacionais();
  
  public BigDecimal calculaImposto(int valor) {
    return this.calculadora.calcula(valor);
  }
}
```

* `MyService` **depende** da classe `CalculadoraDeImpostosNacionais`, pq para executar o `calculaImposto` se faz necessário utilizar o método `calcula` da `CalculadoraDeImpostosNacionais`.

  * O que aconteceria se precissássemos de mais calculadoras? **Talvez `MyService` pudesse receber no construtor a Calculadora?** Sim, mas o ideal seria com uma interface, **pois a interface não exige que seja instanciada,**  tirando assim a **dependência de `MyService` da `Calculadora`**

    ```java
    public interface CalculadoraDeImpostos {
      BigDecimal calcula(int valor);
    }
    ```

    ```java
    public class MyService {
      
      private CalculadoraDeImpostos calculadora;
      
      // constructor
      // quem quiser usar MyService, pode passar a classe que quiser que implemente a interface...
      public MyService(CalculadoraDeImpostos calculadora) {
        this.calculadora = calculadora;
      }
      
      public BigDecimal calculaImposto(int valor) {
        return this.calculadora.calcula(valor);
      }
    }
    ```



### W/ Injeção de dependência - Autowired

* O Spring lida com a injeção de forma diferente. Através de containers chamado `Spring IoC`. Ele consegue manipular todas as dependências.

* **`@Autowired`** (ponto de dependência) -> pode ser utilizada e atributos/Setters

  * ```java
    @Service
    public class MyService {
      
      @Autowired
      private CalculadoraDeImpostos calculadora;
      
      public BigDecimal calculaImposto(int valor) {
        return this.calculadora.calcula(valor);
      }
    }



## Aula 3/4 - DTOs

* DTO ou ***Data Transfer Object*** é nada mais do que uma **abstração da regra de negócio/entidade**.

* Porque usar?

  * Imagine a classe ***User***:

  * ```java
    public class User {
      private String name;
      private Integer age;
      private boolean admin;
    }
    ```

  * Imaginando que temos um controller que salva o usuário, poderíamos **deixar vulnerável nosso sistema**, pois um hacker poderia "tentar" simular no JSON que temos um parametro chamado ***admin*** :thinking:

  * ```json
    {
      'name': 'Igor',
      'age': 27,
      'admin': true
    }
    ```

  * Com o uso de DTO podemos abstrair o parâmetro `admin` , fazendo assim, com que mesmo que seja passado admin no JSON, ele será **ignorado!**

  * ```java
    public record UserDTO(String name, Integer age){}
    ```



Como bom padrão para o DTO, devemos coloca-lo **próximo a Controller!** E seguindo o principío SOLID, o DTO será responsável em retornar a Entidade!

```java
//DTO
public record UserDTO(String name, Integer age){
  
  public User toUser() {
    return new User(name, age)
  }
}


//ENTITY
public class User {
  private String name;
  private Integer age;
  private boolean admin;
  
  public User(String name, Integer age) {
    this.name = name;
    this.age = age;
  }
}
```





# Fase 2 - DDD e Tests

Fast-test:

1. E
2. E
3. E
4. E
5. B

## Aula 1 - Intro Domain Driven Design

* DDD (*Domain Driven Design*) é uma **padrão de design de software**.
* **NÃO PRECISAMOS USAR TUDO DO DDD**;
* Nos ajuda **não sair escrevendo código SEM PLANEJAMENTOS**; (**GOHORSE!**)
* Enfatiza a colaboração com um **domain expert** (uma ou mais pessoas) e um time de desenvolvedores, **para entender o domínio/goal** do projeto;

<img src="./imageResource/subDomain.png" alt="subDomain" style="zoom:50%;" />



### Design Estratégico

* Por quê?
  * Por que fazer XPTO?
* O quê?
  * O quê vamos fazer?
* Como?
  * Último step, no como fazer...

### Subdomínio Principal

*Heart of the business* / *core do negócio*

* Em uma *escola* o **domínio é a educação!** é o Foco, missão principal da escola
* É o que faz o seu projeto **ser** **diferente**;



### Subdomínio de Genérico

É todo **processo em comum com o resto do mercado**, é algo que **não fará diferença** no seu projeto, como:

* Folha de pagamento;
* Contabilidade;
* Autenticação;

É onde fica uma lógica complexa, **mas** que não é a principal...



### Subdomínio de Suporte

* Não afeta teu projeto se isso der problema...
  * O software de Folha de pagamento está fora do ar, **podemos fazer via Excel**;



## Aula 2 & 3 - Storytelling

* Nada melhor do que entender o que **há de ser feito** com um conto de histórias!
* Nada melhor do que uma história escutada por diferentes perspectivas, traga pessoas para contar sobre X assunto;

**Todo domínio** começa com um *conto de histórias*, que contém **atores, objetos e ações**

* **atores:** são as peças fundamentais do domínio; *Cliente, usuário, atendente*
* **objetos**: é o meio, pode ser físico ou digital; *planilha, ticket, sistema de vendas*
* **ação**: é a interação entre **atores e objetos**; Cliente acessa o sistema de vendas;
  * usamos verbos!




Quando usamos *storytelling*, é importante **numerarmos as ações**, para que exista uma ordem naquela história.

* É o caminho feliz, ***sem if-else***
* Utilize **pictogramas**, imagens que ilustram como objetos / ações agem

<img src="./imageResource/ddd2.png" alt="ddd2" style="zoom:50%;" />

**ATENÇÃO:** quando escutamos a história de um ***domain expert***, temos que separar:

* ***AS IS***: como é hoje / realidade atual
* ***TO BE***: como será / desejo / realidade futura



Contar histórias nos ajuda:

* Entender o domínio;
* Estabeler uma linguagem em comum com o Domain Expert e o IT Expert;
* Esclarescer mal entendido;
* Desenhar processos de negócio;



Integrantes principais:

* **Domain expert**: quem irá contar a história
* **Ouvintes:** todos que estão disponíveis a aprender a história (developers);
* **Moderador**: quem irá fazer as perguntas ao domain expert e n deixar o assunto correr;
* **Modelador**: quem irá fazer os pictogramas e fazer as anotações



Outro exemplo com numerações, atores, ações e objetos:

![storytelling](/./imageResource/storytelling.png)

* Precisa descrever um ***if else*** dentro desse fluxo? **CRIE UM NOVO CENÁRIO!**



Novo cenário na visão do **time de admissão**

![storytelling2](./imageResource/storytelling2.png)

* Com anotações/dicionário para entender a linguagem do time!



Mesmo cenário, porém na visão do **time de marketing**

![storytelling3](./imageResource/storytelling3.png)

* Leads = Responsáveis = Pais = Prospects
  * ![storytelling 4](./imageResource/storytelling 4.png)



* É de extrema importância que haja um **a linguagem ubíqua** / linguagem em comum entre os envolvidos de diferentes áreas

Existem ferramentas **WiKi** para nos ajudar a mapear  / catalogar os modelos

* Notion.io

O que é importante de se ter na **WiKi**:

* Wiki central do projeto, que consolida todas as demais wikis;
* Wiki com descrição do projeto;
* Uma página para cada subdomínio (um para cada time do projeto);
* Seção na wiki para **linguagem ubíqua**/**dicionário**;
* Seção para os cenários que criamos, premissas e limitações;
* Link para os repositórios
* Link para ferramenta de gestão do projeto;



## Aula 4 - Contexto Delimitados

Existem diversos modelos de contextos delimitados e como eles se interagem:

* **Parceria**
  * Trabalham juntos, uma mudança é conversada com o outro
  * Em microserviços trabalham com contratos
  * <img src="./imageResource/parceria.png" alt="parceria" style="zoom:50%;" />
* **Kernel Compartilhado:**
  * **Se evite ao máximo!** É quando 2 times trabalham em uma mesma função de sub-domínios/contextos diferentes
  * Comunicação é essencial! Para evitar código duplicado, ou quebrar algo do outro lado
    * <img src="./imageResource/kernel.png" alt="kernel" style="zoom: 50%;" />
* **Cliente Fornecedor**
  * Aceita o que o fornecedor (upstream) faz, se ele altera, o cliente (downstream) altera
    * <img src="./imageResource/clientFornecedor.png" alt="clientFornecedor" style="zoom:50%;" />
* **Camada Anti-Corrupção (ACL)**
  * Faz uma interface de meio de campo, entre o client e o fornecedor, assim se alguma alteração acontece no fornecedor, não precisam todos os sistemas serem alterados
  * Como um JDBC para o Banco
  * <img src="./imageResource/acl.png" alt="acl" style="zoom: 50%;" />
    * AWS possui o Keyclock, que se integra com Google, Facebook e etc, fazendo o. trabalho de ACL para os times
* **Linguagem Publicada (PL)**
  * É o oposto do que acontece com o Cliente Fornecedor. Neste modelo o fornecedor se adequa ao cliente
* **Caminho Separado**
  * Muitas vezes apesar dos contextos terem algo em comum, pode acontecer do business ou time técnico decidirem cada um seguir com o seu desenvolvimento



No Final, iremos ter um **MAPA DE CONTEXTO**, onde se junta diversas camadas e tipos de Contextos (junção de PL, ACL e etc)

![mapa de contexto](./imageResource/mapa de contexto.png)



## Aula 5 - Arquitetura e Lógica

![arqLogica](./imageResource/arqLogica.png)

* **Designed Tático**:

  * É onde fica o `como` do DDD, é a parte prática, aqui definimos a linguagem, tecnologia, tipos de banco de dados (relacionao ou não), microserviços ou barramento e como se interagem

* **Camada de interface de usuário (GUI)**:

  * É onde fica a interface do usuário, interface de comando (CLI) e as APIs

* **Camada de aplicação**:

  * Aqui não fica a lógica de negócio e tbm n se altera estado de objetos, mas fica a parte de monitoramento que irá reportar as mudanças a outras camadas.
  * Aqui ficam os gatilhos de atualização do sistema. (***cronjob***)

* **Camada de Domínio**:

  * É o core da aplicação (conceitos de negócio), aqui ficam os objetos e onde eles são alterados (é oq diferencia a aplicação, ***o segredo***).
    * Exemplo: onde fica a lógica da nota dos alunos, planos de aula e etc

* **Camada de Infra**:

  * É a camada que da suporte as camadas superiores, é onde fica a mensageria por exemplo

  

  ![arqLogica2](./imageResource/arqLogica2.png)

  

## Aula 6 - Event Storming

O Event Storming é a atividade prática, onde chamamos:

* Domain Experts: irá descrever as atividades
* Ouvintes: querem aprender sobre a história (developers)
* Facilitador: que vai conduzir



Nela iremos preencher:

* **EV** -> Eventos (atividades **escritas no passado**);
* **CM** -> Comandos (o que triga o evento, **escrita no presente**);
* **AT** -> Atores (pessoas que executam Comandos);
  * **PL** -> Política (sistema que faz o papel do ator, de trigar algum comando);
* **PA** -> Ponto de Atenção (são as perguntas relacionada ao evento);
* **ML** -> Modelo de Leitura (é a interface)<img src="./imageResource/eventStorming.png" alt="eventStorming" style="zoom: 50%;" />



Dessa forma podemos criar os **agregados**, que são como as entidades irão se conversar

![eventStormingContexto](/Users/igorgomesromerovilela/Development/NotesInGeneral/Java/graduate/imageResource/eventStormingContexto.png)



# Fase 2 - Docker

* O Docker surgiu como uma melhoria da então chamada **Maquina Virtual**
* Para criar uma máquina virtual, é necessário fazer toda a instalação do Sistema Operacional (40 minutos no mínimo);
* Docker vem com o conceito de **container**, onde permite **executar um sistema** de forma isolada com **somente as dependência/bibliotecas daquele sistema**.
* Para configurar um container usamos **Dockerfile**, ali ficará instruções para criação do container!
* **Docker Hub** é o **repositório de imagens**, ali nós podemos subir até mesmo **imagens personalizadas**, ou usar imagens que empresas fornecem (openjdk, python e etc);



## Entendendo comandos

* **`FROM`** -> aqui referenciamos a imagem que vamos usar
* **`WORKDIR`** -> Definimos o diretório que iremos partir (igual ao `cd /folderX`)
* **`RUN`** -> Executa em **tempo de criação da <u>imagem</u>**, qualquer comando, como se estivessemos no terminal
* **`CMD`** -> Executa em **tempo de criação do <u>container</u>** - permite que o comando seja sobreescrito
* **`ENTRYPOINT`** -> Executa em **tempo de criação do <u>container</u>** - NÃO permite que o comando seja sobreescrito
* **`EXPOSE`** -> Utilizado para expor uma porta
* **`COPY`** -> Copia arquivos ou pastas na criação da imagem
* **`VOLUME`** -> Na criação da imagem referenciamos onde irá ficar os metadados;

```dockerfile
FROM ubuntu:22.10

RUN apt-get update
RUN apt-get install nginx -y

VOLUME ["/var/www/html"]

WORKDIR "/var/www/html/"

COPY "index.html" "index.html"

ADD "https://images.pexels.com/photos/1521304/pexels-photo1521304.jpeg" "foto.jpeg"
# Como baixamos o arquivo precisamos alterar a
# permissão para que seja possível acessá-lo
RUN chmod 644 foto.jpeg

ENTRYPOINT ["/usr/sbin/nginx", "-g", "daemon off;"]

EXPOSE 80
```



## Docker Compose

* Precisa gerenciar +1 container?
* Precisa rodar +1 container junto?

Use o **Docker Compose!**

O Docker Compose é configurado **atarvés de um arquivo `docker-compose.yml`**, onde podemos declarar:

* Serviços (db, APIs, frontend, backend) -> aqui vão as imagens do Docker/Dockerfile;
* Volumes
* Secrets
* Portas

### Comandos

| Descrição comando                                        | Comando                                |
| -------------------------------------------------------- | -------------------------------------- |
| Executar Docker Compose com arquivo `docker-compose.yml` | `docker compose up`                    |
| Para não segurar o terminal na execução                  | `docker compose up -d`                 |
| Executar Docker Compose com arquivo customizado          | `docker compose -f FILENAME.yml up -d` |
| Parar Docker Compose                                     | `docker compose down`                  |



### Exemplo

```yaml
services:
  db:
    # We use a mariadb image which supports both amd64 & arm64 architecture
    image: mariadb:10.6.4-focal
    # If you really want to use MySQL, uncomment the following line
    #image: mysql:8.0.27
    command: '--default-authentication-plugin=mysql_native_password'
    volumes:
      - db_data:/var/lib/mysql
    restart: always
    environment:
      - MYSQL_ROOT_PASSWORD=somewordpress
      - MYSQL_DATABASE=wordpress
      - MYSQL_USER=wordpress
      - MYSQL_PASSWORD=wordpress
    expose:
      - 3306
      - 33060
  wordpress:
    image: wordpress:latest
    volumes:
      - wp_data:/var/www/html
    ports:
      - 80:80
    restart: always
    environment:
      - WORDPRESS_DB_HOST=db
      - WORDPRESS_DB_USER=wordpress
      - WORDPRESS_DB_PASSWORD=wordpress
      - WORDPRESS_DB_NAME=wordpress
volumes:
  db_data:
  wp_data:
```



## Docker Network

Como trabalhar compartilhar uma rede entre containers???

* O Docker fornece um driver padrão de rede, chamado **bridge**. Quando não especificamos o tipo de rede, o Docker irá automaticamente criar os containers e associara mesma rede.



Devemos sempre ter alguns cuidados com network:

* Mapear portas iguais! -> irá dar conflito
* Esquecer de mapear as portas! 



### Comandos

Para criar uma rede customizada:

```bash
docker network create my-test
```

Para associar um container já existente a uma rede

```bash
docker network connect minha-rede meu-container
# docker netword connect my-test frontend-app
```



### Exemplo

```bash
#irá criar uma rede chamada 'shared-network'
docker network create shared-network

#irá iniciar um BancoDeDados na rede 'shared-network'
docker run --name db --network shared-network -e POSTGRES_PASSWORD=password -d postgres

#irá iniciar um App Python  na rede 'shared-network'
docker run --name python-app --network shared-network -d python:3.8 bash

#Acessa o app python e instala as libs
docker exec -it python-app bash
pip install psycopg2-binary
```

De dentro do container `python-app` iremos criar um código python que irá **acessar o container `db`**

```python
import psycopg2

conn = psycopg2.connect(
    host="database",
    database="postgres",
    user="postgres",
    password="password")

cursor = conn.cursor()
cursor.execute("SELECT * FROM <table_name>")
rows = cursor.fetchall()	

for row in rows:
    print(row)

conn.close()
```

Com arquivo criado:

```bash
python <nomedoarquivo>.py
```



# Fase 3 - Deploys



## Deploy local

No java, o deploy local se dá pelo `jar` file, gerado pelo `mvn build` (dentro da pasta `target`).

* Executando o programa (necessário java instalado):

```java
java -jar nomeDoSeuJar.jar
```

* O `war` é para subir no Tomcat;



Com Docker:

```dockerfile
FROM maven:3.8.4-openjdk-17-slim AS build

WORKDIR /app

COPY . /app

RUN mvn package

FROM openjdk:17-jdk-slim

COPY --from=build /app/target/*.jar /app/app.jar

ENTRYPOINT ["java", "-Djava.security.egd=file:/dev/./unrandom", "-jar", "/app/app.jar"]
```



```bash
docker build -t nomeDaImagem .
docker run -d -p 3000:80 nomeDaImagem
docker logs serieDoContainer
```



## Deploy no ECS (AWS)

ECS (**Elastic Container Service**) é um serviço de container da AWS (SaaS - não precisamos gerenciar containers e etc, ele faz para nós) .

* Para subir a imagem a AWS também oferece o ECR (**Elastic Container Registry**), funciona igual ao **Docker Hub**



### Clusters

O Cluster é um grupo que iremos ter:

* Tipo de EC2 (tipo daque mina)
* Networking



### Task Definition

Aqui vinculamos qual a imagem que será utilizada para criar o app.

* Clique em ***Create Task Definition***
  * **Fargate** -> Para trabalhar com serveless (por requisição)
  * **EC2** -> sobe uma máquina (até 750h sem custo) - mais comum de uso
* Clique em EC2;
* Clique em Add Container;
  * Preencha o nome do container
  * Nome da imagem no docker hub ou no ECR;
  * Mínimo de memória utilizado
  * Portas
  * Variável de ambiente
  * Política de reinicialização



### Service

O Service precisa de uma task, é onde iremos declarar:

* número de Tasks que serão executadas em paralelo
* LoadBalancer

É onde se faz o link entre a Task e o Cluster.



No Service a gente pode configurar o tipo de `Capacity Provider`:

* FARGATE_SPOT é 5x mais barato que o FARGATE, porém a AWS pode matar o serviço a qualquer momento (mas sobe outro), como se fosse um leilão -> **indicado para DEV/STG**



## Deploy Azure (Microsoft)

Conta: https://azure.microsoft.com/pt-br/free/students/ (100$ disponível)



### Web App for Containers

Serviço feito implantar e executar aplicativos em containers.

Possui algumas facilidades:

* Fácil implantação
* Escalabilidade automática
* Integra com outros services da Azure
* Para container simples ou docker-compose



### Azure Container Instance (ACI)

Serviço também de implementar container, porém sem a necessidade de gerenciar a infra (como no ***Web App For Containers***).

Este serviço é ideal para:

* Apps com curta duração;
* Executar de forma isolada;
* Processamento de eventos;
* Apps que não exigem escalabilidade



### Azure Container Apps (ACA)

Cria containers sem um servidor, e se integra com Docker Hub e outros repositórios.

* Não exige necessidade de gerenciar infra
* Serviço serveless da Azure
* App baseado em container



## Deploy Cloud Gratuita

### Render

https://dashboard.render.com/

Render possibilita nos integrarmos com um repositório do GitHub e a partir dele realizar o deploy!

* Necessário ter o Dockerfile

<img src="./imageResource/render.png" alt="render" style="zoom: 33%;" />

**Camada Free**: 512mb / 0.1CPU

* Projeto vinculado com o git, então a todo commit, irá gerar um update na imagem

Projeto ficará com a URL: https://nomedoprojeto.onrender.com



### Heroku

https://www.heroku.com/



### Supabase

https://supabase.com/

É um servidor free para banco de dados

# Fase 3 - Serverless

Ter um servidor on-premisses, significa ter que cuidar de diversas coisas:

* Garantir escalabilidade
* Segurança
* Infraestrutura (times e times de DevOps)
* MUITA PREOCUPAÇÃO

Como começar? com POCs, migrando em partes!



## Serviços Serverless AWS

**IAM**

É onde a gente cria usuário que irão trabalhar em nossos projetos

* Não é uma boa prática usar o usuário root criando instancias e etc
* Cada usuário irá ter uma `access key` , usada para se autenticar

**AWS Lambda:**

* Executa código sem a necessidade de gerenciar servidores;
* Executa pequenas funções criadas por nós
* Executa tarefa que tem curta duração
* Consultar banco, consultar cache
* Funciona com diversas linguagens;
* Invés de deixar um app que irá executar uma função somente um horário (cronjob), pode ser usado Lambdas;
* **Limitado a 15 minutos de execução** por função;
  * Limitado a 3GB de memória;

**AWS Fargate:**

* Executa containers sem a necessidade de servidor;
* **ECS** (Elastic Container Service):
  * Usa o Fargate para executar containers;
  * ou usa o EC2 para executar containers;
  * Mais caro do que EKS, por ser mais prático e fazer coisas para você
* **EKS** (Elastice Kubernetes Service)

**AWS EventBridge:**

* Serviço de integração;
* Step Functions:
  * Pode se criar flows, de uma lambda para S3 e etc

**AWS AppSync**:

* App que possibilita o frontend consumir direto do banco (sem precisar do backend)
* Baseado GraphQL:
  * Funciona com Pub/Sub, mandamos um request e escutamos uma resposta
  * Houve change no banco, recebemos na hora e avisamos o user;

**AWS SQS (Simple Queue Service)**

* Recebe uma mensagem, poem na fila e o consumidor consome;
* Parecido com MQ;

**AWS SNS (Simple Notification Service)**

* Recebe uma notificação e possui vários consumidores consumindo ou também transmite para outra notificação;
* Cria tópicos e pode publicar para um SQS
* Pub/Sub

**AWS API Gateway**:

* Cria endpoints RESTFul para apps sem a necessidade de servidor;
* Executa funções criadas por nós
* Porta de entrada da aplicação
* HTTP API - gerencia as rotas do app
* WebSocket - fica em tempo real rodando
* Por padrão e segurança, se deixa somente o API Gateway público e os demais serviços privados;



Armazenamento:

**AWS EFS (Elastic File System)**:

* Serverless;
* Escalável;
* Volume -> Compartilha informações entre containers;
* Arquivos temporários;

**AWS S3**:

* Escalável;
* Para guardar arquivos como fotos, site estático;
* Fornece APIs para poder armazenar files;



Banco de dados:

**AWS DynamoDB (NoSQL)**:

* Escalável;
* Serverless;
* Se adapta ao fluxo (conexão disponível);
* Parecido com o MongoDB (NoSQL);

**AWS RDS (Relational Data Service)**:

* Pode ser Serverless ou podemos setar as configs do banco de dados;
* Podemos configurar o mínimo;

**AWS Neptune (Graph Database)**:

* É o Banco de dados feito com a idéia de gráficos;
* Relacionamento são criados conforme criação do banco;



Análise de Dados:

**AWS RedShift**



## Custos

Quando migramos do on-premisses para Cloud, **precisamos fazer uma POC para estimar custos**.

Exemplo - ***Empresa de venda de ingressos:***

<img src="./imageResource/awsLambda.png" alt="awsLambda" style="zoom:50%;" />

* API Gateway filtra a req da internet e direciona para Lambda (meio de campo)
  * Faz autenticação e etc
* Lambda irá executar uma função, q pode ser o GET no banco;
* DynamoDB é o Banco que ajusta automaticamente os recursos;



### Lamda

Gratuito:

* 1MM Requests por mês;
* 400GB-seg de tempo computação por mês;

Demais cobranças:

* Por segundo baseado na memória/recurso disponibilizado;
  * Dividido em ARM ou X86
* Armazenamento temporário outros preços;



Para Lamda, o ideal que seja um procssamento rápido, se for demorar, ideal é utilizar containers;

* 15 Min limite;



### API Gateway

Gratuito:

* 1MM de chamadas API por 12 meses;

Custos:

* Divididos em:
  * API RESTFul
  * Websocket
* Baseado na região o preço irá mudar também
* Cobrado por numero de requisições ou **por tempo de execução**
* Armazenamento em Cache, cobrado por GB/hora



### DynamoDB

Gratuito:

* 25GB de armazenamento

Tipos de cobrança:

* On demand: será cobrado por demanda, pode ser baixa ou alta
* Provisionado: já sabemos o quanto iremos usar, mais barato



### AWS Pricing Calculator

É uma calculadora que dá estimativas de preço, nela podemos:

* Selecionar o serviço (lambda, api gateway);
  * Estipular a região;
* número de requisições mês;
* Tipo de máquina (arm/x86);
* Tempo de cada requisição (ms);



## AWS CLI

Além da opção via UI, a AWS fornece meios de criarmos/manipularmos os recursos via CLI: https://aws.amazon.com/pt/cli/

Para utilizar, primeiro precisamos configurar as credenciais:

* Vá para o https://aws.amazon.com/ -> Sign in
* Clique no profile -> Security Credentials
* Create access key
* No Terminal -> `aws configure` e coloque o access key com a chave



## Containers na AWS

Quando temos alguma execução que irá levar mais de 15 minutos, **não podemos usar Lambda**, e para isso a Amazon oferece:

* ECS
* ECR

Junto com o API Gateway podemos expor esse serviço do ECS (que estará rodando com um container)

### ECR

O ECR nos permite subir uma imagem Docker para um registry da amazon, facilitando nossa vida para fazer depois o deplou no ECS

* Com terminal aberto e o AWS CLI configurado:

```bash
aws ecr --region us-east-1 create-repository --repository-name test
```

* O comando irá devolver a URL com o repository, agora basta subirmos no Docker Hub

```bash
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin pasteHereURl
```

```bash
docker tag nomeDaImagemBuildada pastHereECRURL/nomeDaImagemBuildada
docker push pastHereECRURL/nomeDaImagemBuildada
```



### ECS

ECS serve para **Orquestrar a execução de tarefas em containers de forma serverless.**

1. Criar um cluster (conjunto de recursos operacionais)
2. Criar uma task definition (é onde configuramos os recursos/parametros do container)
   1. Configuramos:
      1. URL da imagem (ECR)
      2. Porta
      3. Variável de ambiente
      4. Recurso de ram e cpu
      5. Arquitetura do build da imagem Docker (atenção ao tipo, no mac é ARM64)
      6. Número de containers
      7. HealthChecks
3. Criar um Service (é onde de fato irá publicar/expor o container com os valores definidos na Task Definition)
   1. Configuramos:
      1. Network
      2. LoadBalancer
      3. Replicas
      4. AutoScaling

Com um Service criado, será exposto um IP Publico de acesso ao ECS!

* Task Execution Role é a função do agente que orquestra/gerencia o container



### API Gateway

Para expor uma API precisamos levar em conta algumas coisas, como:

* Auth
* Rotas/Direcionar rotas

Para iniciar com o API Gateway, precisamos primeiro entender sobre **VPC (Virtual Private Cloud)**



#### VPC (Virtual Private Cloud)

* VPC funciona como uma rede privada da nossa casa, onde teríamos um roteador e vários outros computadores se conectariam via LAN

Exemplo completo:

<img src="./imageResource/vpc.png" alt="vpc" style="zoom:50%;" />

**Criando uma VPC**

1. Iremos precisar informar:
   1. Qual region iremos ter a VPC (us-east-1a/b/c)
   2. Número de subnets público e privado
   3. Se queremos uma VPC exclusiva (placa de rede física dedicada)

**Security Group**

Para controlar o range de IP ou quem acessa tanto o LoadBalancer quanto os clusters, criamos o chamado **Security Group**, e dessa forma mapeamos como componentes se comunicar dentro de uma VPC!

EXEMPLO:

1. Criar um Security Group para LoadBalancer (tudo que for loadbalancer usaria o mesmo grupo)
   1. Em **Inbound rules**, permitiríamos que todo mundo entrasse *Anywhere-ipv4
   2. En **Outbound rules**, permitiríamos que todo mundo entrasse *Anywhere-ipv4
2. Agora para o **Security Group do Cluster**, não permitiríamos o **Inbound** para anywhere, e sim para o **SecurityGroup do LoadBalancer**, assim, garantíamos que somente o loadbalancer acesse os cluters



#### Target Group

Para criarmos um LoadBalancer, precisamos primeiro de um TargetGroup.

Para criar um Target Group precisamos ir em EC2, e ali iremos configurar para `IP Addresses` (uma vez que o ECS se comunica via IP).



#### LoadBalancer

Por se tratar de um uso para o API Gateway, devemos configurar **como Interno**

#### Cluster

Como uma Security Group ja criado, iremos **criar um Cluster** **usando o Security Group do cluster.**

Com o Cluster criado, podemos **aproveitar a Task Definition** que já tivemos e **criar um Service**, também usando a subnet e vpc privada, feita usando os security group do Cluster VPC, e também usando o loadbalancer já criado

#### Criando API Gateway

Com VPC + Security Group (p/ LB e Cluster) + Target Group + LoadBalancer + Cluster/Services criados, está na hora de mapearmos um API Gateway!

* Em **API Gateway**, vamos em `buil` um **HTTP API**, e colocamos o nome da API Name, e `create` -> irá já expor uma URL pública
* Em **Routes**, iremos mapear um ANY -> `/{proxy+}` - dessa forma qualquer nova rota irá usar essa integração.
* Em **Integrations**, iremos criar um `Private Resource` -> Target service como **ALB/NLB** (appliacation lb e network lb)



## Autenticação

### Amazon Cognito

* 50K users ativos por ano é gratuito
* Permite MFA
* Acesso via redes sociais (google, Facebook e etc)!
* Disponibiliza formulário de preenchimento
* Pode segregar usuários (admins e users comuns)
* Possibilita migração
* Escalável



**Criando User Pools**

User Pools é onde colocamos as configs de cadastro dos usuários.

1. **Provider Types**: Cognito user Pool + Federated identify (acesso com Google etc)
2. **Sign in options**: Tipos de sign in, como **por email/usuários/phone**;
3. **Password policy**: Podemos configurar qual tipo de senha;
4. **MFA**: por ou não por MFA
5. **Recover**: podemos setar como recuperar a senha;
6. **Self signup**: permitir que o usuário se cadastre;
   1. Aqui podemos colocar até 50 tipos de atributos do usuário;
7. **Domain**: podemos integrar uma tela ja existente, ou criar uma do cognito do zero

<img src="./imageResource/cognito.png" alt="cognito" style="zoom:30%;" />



## Lambda

Lambda não cobra, mas conforme o uso, ele cobra pelo uso de RAM e CPU

* Lambda recomendado para coisas que não tem uso contínuo!
  * Fez uma chamada, ela retorna de forma rápida algo, não é para ser usado para grande processamento



No lambda iremos colocar **literamente um código!** e este código será executado pela AWS



**Criando Lamda**:

* **Create function**:
  * **Blueprint**, a AWS dá diversos exemplos prontos (chamados **blueprints**) que são códigos prontos para serem executados

<img src="./imageResource/lambdablueprint.png" alt="lambdablueprint" style="zoom:50%;" />

* ​	**Author from scratch**: colocamos a linguagem

* Selecionamos o tipo de arquitetura que será utilizado
* **Lambda function code**, é onde ficará o lamda q será executado

<img src="./imageResource/lambdafunction.png" alt="lambdafunction" style="zoom:50%;" />



## SAM

Deseja testar, criar e implantar aplicativos serverless? AWS oferece o SAM (**Serverless Application Model**)!

* Através de um YAML é possível configurar o ambiente





# Fase 3 - NoSQL MongoDB

* **NoSql** = ***Not Only SQL***
* O MongoDB é um sistema NOSQL
* Ao invés de utilizar dados relacionais, é utilizado o formato JSON ou BSON (binary Json);
* Orientado a Documentos;
* Fornece alta disponibilidade/tolerância falhas;
* Suporta QREP;
* Suporta consulta avançada, incides;

**Estrutura:**

```
Da		tabase
		|_______ Colections
									|_______ Documents
```



## NoSql X Sql

* Quando queremos mais desempenho? 

* O NOSQL NÃO SUBSTITUI O SQL;

* Precisa lidar com dados não estruturados ou semi estruturados?

* Precisa de uma alta velocidade de leitura e gravação?

* Precisa de flexibilidade?

  * Um Documento pode conter:

    * ```json
      {
        "_id":"123",
        "name":"Igor",
        "age":27
      }
      ```

  * Como pode ter:

    * ```json
      {
        "_id":"123",
        "age":27
      }
      ```



### Vantagens NoSql

A maior vantagem do NoSql em relação SQL se dará muito em **como o dado foi estruturado usando NoSql**!

Vamos imaginar a página abaixo:

<img src="./imageResource/nosqlarticle.png" alt="nosqlarticle" style="zoom:30%;" />

* Podemos ter:
  * Autor
  * Artigo
  * Categoria
  * Comentários

Utilizando o SQL teríamos:

<img src="./imageResource/sqlArticle.png" alt="sqlArticle" style="zoom:50%;" />

* Para exibir uma tela, teríamos que realizar pelo menos 3 consultas!

```sql
SELECT artigos.*, autor.name FROM artigos
INNER JOIN autor ON autor.autor_id = artigos.audtor_id
WHERE artigo_url = 'xyz';

SELECT categoria.*, autor.name FROM categoria
INNER JOIN artigo_categoria ON artigo_categoria.idCategoria = categoria.id
WHERE artigo_categoria.id = 'xyz';

SELECT comentario.* FROM comentario
WHERE comentario.artigo_id = 'xyz';
```



Com **NoSql os dados podem e devem ser duplicados em um único documento**!

* Pelo NoSql ser muito performático, o melhor uso dele é colocar tudo que uma tela precisa em um único documento
  * **ATENÇÃO!** quando for atualizar o nome do Autor por exemplo, precisará atualizar todos documentos de outras collections que possuem o nome daquele Autor!

```json
{
    _id: ObjectId("64a495d6896e49abd95879e8"),
    title: 'Title do artigo',
    categoria: "Categoria x", 
    author: {
      "_id": ObjectId("123")
       "name": "Igor Romero",
       "email": "igorgrv@hotmail.com"
 		},
    comentarios: [
      {
	      "_id": ObjectId("123"),
        "body":"meu comentario"
      }
    ]
}
```



## Tipos de relacionamentos

Sim, Nosql tem relacionamentos!

* Incorporação
* Referência (referencia chave valor, um documento vai ter a chave do outro)
* Desnormalização

### Incorporação

Quando um Documento incorpora/possui outro documento

Exemplo - **Usuário vs Postagens**

```json
{
  "_id": ObjectId("user1"),
  "nome": "João",
  "idade": 25,
  "postagens": [
    {
      "_id": ObjectId("post1"),
      "titulo": "Primeira postagem",
      "conteudo": "Conteúdo da primeira postagem"
    },
    {
      "_id": ObjectId("post2"),
      "titulo": "Segunda postagem",
      "conteudo": "Conteúdo da segunda postagem"
    }
  ]
}
```



### Referência:

Como o nome diz, um documento referencia o outro por Id:

```json
{
  "_id": ObjectId("user1"),
  "nome": "João",
  "idade": 25,
  "postagens": [
    ObjectId("post1"),
    ObjectId("post2")
  ]
}
```



### Desnormalização

Basicamente se trata de **duplicar dados** de um documento em vários, para melhorar o desempenho das consultas (evitando buscas em diversos documentos)

* Usado quando pensamos no que uma página irá exibir (trazemos somente as informações q a página precisa);
* Útil quando se tem consultas frequentes, que exigem acesso rápido aos dados;
* Melhora o desempenho das consultas
* **Contras: ocupa mais espaço no banco e cria redundância de dados**

Exemplo - trazer a última postagem do usuário:

```json
{
  "_id": ObjectId("user1"),
  "nome": "João",
  "idade": 25,
  "ultimaPostagem": {
    "_id": ObjectId("post2"),
    "titulo": "Segunda postagem",
    "conteudo": "Conteúdo da segunda postagem"
  }
}
```



## Instalando CLI

MongoDb Community Server: https://www.mongodb.com/try/download/community

Mac: 
```shell
$ brew install mongodb-atlas
$ atlas setup
```

Depois de instalar, tente:

```bash
mongosh
```

Se retornar
```bash
➜  /usr mongosh
Current Mongosh Log ID:	651f5f0ce4f49732716ff4f7
Connecting to:		mongodb://127.0.0.1:27017/?directConnection=true&serverSelectionTimeoutMS=2000&appName=mongosh+2.0.1
MongoNetworkError: connect ECONNREFUSED 127.0.0.1:27017
```

Tente pausar e restartar:

```bash
brew services stop mongodb-community
brew services start mongodb-community
```

Resultado esperado:

```bash
➜  /usr mongosh
Current Mongosh Log ID:	651f5f27e507f33d557300d4
Connecting to:		mongodb://127.0.0.1:27017/?directConnection=true&serverSelectionTimeoutMS=2000&appName=mongosh+2.0.1
Using MongoDB:		7.0.2
Using Mongosh:		2.0.1

For mongosh info see: https://docs.mongodb.com/mongodb-shell/

------
   The server generated these startup warnings when booting
   2023-10-05T22:13:11.933-03:00: Access control is not enabled for the database. Read and write access to data and configuration is unrestricted
------

test> show databases
admin   40.00 KiB
config  12.00 KiB
local   40.00 KiB
```



## Instalando MongoDb Compass

Link: https://www.mongodb.com/try/download/compass

<img src="./imageResource/mongodbCompass.png" alt="mongodbCompass" style="zoom:80%;" />

## Comandos

* Iniciar servidor mongo: **`mongod`**

* Mostrar banco: **`show databases`**

* Selecionar o banco: **`use nomeDoBanco`**

* Criar collection: **`db.createCollection("nomeColecao")`**

  * Precisa estar no banco, com o `use`

* Mostrar colections: **`show collections`**

* Deletar collection: **`db.nomeCollec.drop()**

* Count documentos de uma collection: **`db.nomeCollection.countDocuments()`**

* Listar documentos: **`db.nomeCollection.find()`**

* Listar com filtro: **`db.nomeCollection.find({},{})`**

  * Find recebe 2 parâmetros:

    * 1. parâmetro: se `{}` irá trazer todos os documentos, seria nosso `WHERE` 
      2. parâmetro: é o que queremos ver, seria nosso `SELECT`

    ```json
    db.customers.find({}, {"_id": 0})
    // significa que queremos todos documentos
    // mas que não mostre o _id
    
    db.customers.find({}, {"_id": 1})
    // irá exibir somente o _id
    ```

  * `LIKE` no NoSql é feito pelo `//`

    ```json
    db.customers.find({nome: '/I/'})
    // podemos por 'i' ao final, para ignorar camelCase
    db.customers.find({nome: '/I/i'})
    ```

  * StartsWith é feito pelo `/^/`

    ```json
    db.customers.find({nome: '/^Ig/i'})
    ```

  * `>=` -> Greater than

    ```json
    db.customers.find({idade: {$gte: 18}})
    ```

  * `AND` por mais de uma busca

    ```json
    db.customers.find( { idade: {$gte: 18}, nome: {$regex: /i/} })
    ```

  * Baseado em um objeto dentro de um **objeto**

    ```json
    // dado: { _id: 123, autor: { nome: igor} } -> busque este elemento
    db.customers.find( {"autor.nome": "igor" })
    ```

  * Baseado em um objeto de um **array**:

    ```json
    // dado: { _id: 123, tags: ["tag1","tag2"] } -> busque tag2
    db.customers.find( {tags: "tag2"})
    ```

* Count + Find: **`db.nomeCollec.find( {atributo: valor} ).count()`**

```json
db.customers.find( {idade: {$gt: 40} } ).count()
```

* Find + Range: **`db.nomeCollec.find({atributo: {$ind:[x,u]} })`**

```json
db.customers.find({idade: {$in:[1,4]} })
```

* Add um documento: **`db.nomeCollection.insertOne({ nome: "test" })`**

* Add vários documentos: **`db.nomeCollection.insertMany([{ nome: "test" },{ nome: "test2" }])`**

  * MongoDb permite criar variáveis temporárias:

    ```bash
    custArray = [{ nome: "test" },{ nome: "test2" }]
    db.customers.insertMany(custArray)
    ```

* Ordernar um documento: **`db.nomeCollection.find().sort({atributo: 1})`**

  * se `1` -> ASC

  * se `-1` -> DESC

    ```json
    db.nomeCollection.find().sort( {nome: 1} )
    ```

* Atualizar um doc: **`db.nomeCollection.replaceOne( {atributo: 'valorAntigo'}, {atributo: 'valornovo'})`**

```json
db.nomeCollection.replaceOne( {nome: 'Igor'}, {nome: 'Igor2', idade: 23})
```

*PERIGOSO! O ideal é fazer um **UPDATE com WHERE***

* Atualizar doc pela chave: **`db.nomeCollection.updateOne( {_id: 123}, {$set: {atrib: valor} })`**

```json
// $set -> altera o dado do elemento/ou inclui caso n exista
// dado: { _id: 123, nome: Tiago }
db.customer.updateOne( {_id: ObjectId("123")}, {$set: {nome: "Igor", Idade: 2} })
// após o set: { _id: 123, nome: Igor, idade: 2}
```

* Atualiza o subdocumento

  ```json
  // dado: { _id: 123, autor: {nome: Igor} } -> troque nome do autor
  db.customer.updateOne( {_id: ObjectId("123")}, {$set: {"autor.nome": "Tiago"} })
  ```

  

* Atualizar TODOS doc: **`db.nomeCollec.update( {}, {$set: {att: valor}}, {multi:true})`**

```json
db.customers.update( {}, {$set: {idade: 0}}, {multi:true})
```

* Remover um campo: **`db.nomeCollection.updateOne( {_id: 123}, {$unset: {atrib: "valor"}})`**

```json
// $unset -> remove o atributo
db.customer.updateOne( {_id: 123}, {$unset: {cidade: "rj"}})
```

* Adicionar um objeto a um array: **`db.nomCol.updateOne( {_id: 123}, {$push: {atrib: "valor"}})`**

```json
// push add objeto a um array
// dado: { title: test, comentario: [] }
// add um objeto array 'comentario'
db.post.updateOne( {_id: 123}, {$push: {comentario : {title: comentTitle} } })
```

* Remover um objeto de um array: **`db.nomCol.updateOne( {_id: 123}, {$pull: {atrib: "valor"}})`**

```json
// $pull remove objeto de um array
// dado: { title: test, comentario: [ { title: comentTitle} ] }
// remova o comentario 'comentTitle'
db.nomeCollection.updateOne( {_id: 123}, {$pull: {comentario : {title: comentTitle} } })
```

* Deletar um doc: **`db.nomeCollection.deleteOne( {atributo: valor} )`**

```json
db.customers.deleteOne( {_id: ObjectId("id")} )
```

* Distinct: **`db.nomeCollec.distinct("atributo")`**

```json
db.customers.distinct("nome")
```

* Count Docs if Exists: **`db.customers.find( {attr: {$exists:true} }).count()`**

```json
db.customers.find( {"nome":{$exists:true}} ).count()
```

* Data: **`ISODate("2023-10-01T01:00:00.00Z")`**

* GROUP BY: **`db.nomeCollec.agregate(operations)`**

  * No exemplo abaixo iremos agregar pelo nome, e queremos fazer uma soma dos counts

    * ```json
      db.customers.agregate( [ {$group: {_id: "name", num_tutorial: {$sum: 1} } } ] )
      ```

  * Se quiseremos somar pelo field `likes`:

    * ```json
      db.customers.agregate([{$group: {_id: "name", num_tutorial: {$sum: "$likes"} }}])
      ```

* INNER JOIN: **`db.nomeCollec.agregate([{ $lookup:{} }])`**

  ```json
  // dado as 2 collections: ORDERS & PRODUCTS faça o innerJoin
  // Order: { _id: 1, productId: 101}
  // Product: { _id: 101, name: "xbox", category: "eletronic"}
  
  db.orders.agregate([{
    $lookup: {
      from: "products",
      localfield: "productId",
      foreignField: "_id",
      as: "product"
    }
  }])
  ```

  * `$project` -> serve para filtrar o que queremos ver do `$lookup`:

    ```json
    db.orders.agregate([{
      $lookup: {
        from: "products",
        localfield: "productId",
        foreignField: "_id",
        as: "product"
      }
    }, {
      $project: {
        _id: 0,
        productName: "$product.name"
      }
    }])
    ```

  * `$match` -> serve para fazer um filtro (`WHERE`) no INNER JOIN:

    ```json
    db.orders.agregate([{
      $lookup: {
        from: "products",
        localfield: "productId",
        foreignField: "_id",
        as: "product"
      }
    },
    {
      $match: {
        "product.category":"eletronics"
      }
    },
    {
      $project: {
        _id: 0,
        productName: "$product.name"
      }
    }])
    ```











